{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7367044e",
   "metadata": {},
   "source": [
    "# **<u>Part 3</u>:** The best of two worlds: fast and readable Python.\n",
    "\n",
    "### \n",
    "\n",
    "### A GitHub analysis shows that `Python` is among the most expressive\n",
    "### general purpose programming languages in existence.\n",
    "### \n",
    "### Expressiveness means fewer lines of code and fewer changes per commit.\n",
    "### \n",
    "### Expressiveness comes at a cost: <u>performance</u>.\n",
    "### \n",
    "### `Python` is <u>slow</u>. Very slow. A pure `Python` implementation is typically\n",
    "### $\\sim 10$ to $\\sim 100$ times slower than an equivalent `C` implementation, for instance.\n",
    "### \n",
    "### Then why is `Python` arguably the most important language in scientific computing,\n",
    "### a domain wherein performance matters the most ?\n",
    "\n",
    "### \n",
    "### \n",
    "### \n",
    "### \n",
    "### 1. It is a misconception that performance matters a lot in scientific computing.\n",
    "### Usually, readability (`Python` is closest to `pseudocode`) > performance (debatable).\n",
    "### \n",
    "### 2. The `Python` programming language is one of the best suited languages for interfacing\n",
    "### performant languages (`Cython`, `Fortran`, `C`, `C++`, `Rust`, ...).\n",
    "### This has lead to a very rich ecosystem of quite performant scientific computing libraries\n",
    "### (`Numpy`, `Scipy`, `PyTorch`, ...) that combine the readability and ease of use of `Python`\n",
    "### with the performance of a compiled language (usually `C` or `Fortran`).\n",
    "### \n",
    "### Some say that `Python` is the _glue_ that holds all other languages together.\n",
    "### \n",
    "### This lecture teaches us the use of `Python` built-in and external modules that can speed up\n",
    "### our code considerably, without sacrificing too much readability.\n",
    "### \n",
    "### Before we venture on, here some artwork:\n",
    "### \n",
    "<img src=\"img/tree_final.png\" alt=\"Drawing\" width=\"700\"/>\n",
    "\n",
    "### \n",
    "\n",
    "### \n",
    "### <u>My code is slow. What should I do</u> ?!?\n",
    "### \n",
    "### Here, a very subjective hierarchy of steps you can take:\n",
    "### \n",
    "### 1. Have a beer (arguably the most comfortable solution).\n",
    "### 2. Improve your `Numpy` skills or write a parallelised code in `Python`.\n",
    "### 3. Use `JIT`-compiled libraries like `Numba` (general purpose) or `JAX` (anything related to optimisation).\n",
    "### 4. Learn the creole language `Cython`.\n",
    "### 5. Use the `ctypes` built-in module to interface a `C` code.\n",
    "### 6. Interface `C++`, `Rust`, `Fortran`, `...`\n",
    "### \n",
    "### If you feel like you need `C++` instead of `C / Cython / Numba`, \n",
    "### you might soon reach a point  where it makes sense to rewrite everything in `C++`\n",
    "### and the `Python` interface becomes a mere afterthought.\n",
    "### \n",
    "### <u>Remember</u>: \n",
    "### Each optimisation may sacrifice readability / flexibility. \n",
    "### Use it with care. Often you will find, you actually don't really need it.\n",
    "### \n",
    "### _\"Premature optimization is the root of all evil.\"_\n",
    "### - Donald Knuth\n",
    "### \n",
    "### _\"Python where we can, C where we must.\"_\n",
    "### - Sergey Brin (Google)\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "# <u>Lesson 1</u>:\n",
    "## Advanced `Numpy` concepts.\n",
    "### \n",
    "### Once you grow tired of the _'have a beer'_ solution, the next step you should take is pimping your use of `Numpy`.\n",
    "### <u>Here is why</u>: making good use of `Numpy` does not only speed up your code, it also typically makes it more `readable`.\n",
    "### \n",
    "### Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5de338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  Four different functions that operate on an array\n",
    "  of shape (n0, n1, ..., nM-1, nM) and return an array of shape\n",
    "  (n0, n1, ..., nM-1) that takes the l2 norm along the last axis.\n",
    "  \n",
    "  The shape of the array (number of dimensions) is only known at runtime.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" BAD implementations first \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - the non-idiomatic implementation requires a number of fail checks to work exactly right \"\"\"\n",
    "def compute_l2_norm_along_last_axis_very_bad(arr: np.ndarray | Sequence) -> np.ndarray:\n",
    "\n",
    "  # remember, you have no idea what the shape of the array is\n",
    "    \n",
    "  arr = np.asarray(arr)  # do local coercion\n",
    "  shape = arr.shape      # (n0, n1, .., nM)\n",
    "\n",
    "  assert arr.ndim >= 1, \"Expected the array to have at least one dimension.\"\n",
    "\n",
    "  \n",
    "  # Since we don't know the number of dimensions,\n",
    "  # we have to flatten the first couple of axes \n",
    "    \n",
    "  # don't use np.prod (product), there is a better way (see below)\n",
    "  arr = arr.reshape((np.prod(shape[:-1]), shape[-1]))\n",
    "  \n",
    "  ret = np.zeros(arr.shape[:-1], dtype=float)\n",
    "  \n",
    "  for i in range(len(ret)):\n",
    "    val = 0.0\n",
    "    for j in range(len(arr[i])):\n",
    "      val += arr[i, j] ** 2\n",
    "      \n",
    "    ret[i] = val ** .5\n",
    "  \n",
    "  return ret.reshape(shape[:-1])  # reshape \n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - a bit better \"\"\"\n",
    "def compute_l2_norm_along_last_axis_bad(arr: np.ndarray | Sequence) -> np.ndarray:\n",
    "\n",
    "  arr = np.asarray(arr)\n",
    "  shape = arr.shape\n",
    "  \n",
    "  arr = arr.reshape((-1, shape[-1]))             # -1 infers the remaining dimension\n",
    "  \n",
    "  ret = np.empty( arr.shape[:-1], dtype=float )  # allocating empty array is faster than zero array\n",
    "  \n",
    "  for i, subarr in enumerate(arr):               # iterate over array directly rather than using a range\n",
    "    ret[i] = (subarr ** 2).sum() ** .5           # avoid the second for loop using vectorisation\n",
    "    \n",
    "  return ret.reshape(shape[:-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Now the `good` ones \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - We don't need fail checks. Will fail if `arr` doesn't have the right shape. \"\"\"\n",
    "def compute_l2_norm_along_last_axis_good(arr: np.ndarray) -> np.ndarray:\n",
    "  return np.sqrt((np.asarray(arr) ** 2).sum(-1))\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - idem \"\"\"\n",
    "compute_l2_norm_along_last_axis_idiomatic = lambda arr: np.linalg.norm(arr, ord=2, axis=-1)\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "\n",
    "A = np.random.randn(5, 4, 2, 3, 20)  # an array with some random shape\n",
    "\n",
    "\n",
    "norm0 = compute_l2_norm_along_last_axis_idiomatic(A)\n",
    "\n",
    "\n",
    "# check if all implementations give the same outcome\n",
    "allfuncs = (compute_l2_norm_along_last_axis_very_bad, \n",
    "            compute_l2_norm_along_last_axis_bad,\n",
    "            compute_l2_norm_along_last_axis_good,\n",
    "            compute_l2_norm_along_last_axis_idiomatic)\n",
    "\n",
    "\n",
    "print(f\"All implementations are the same: {all(np.allclose(norm0, f(A)) for f in allfuncs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511e264",
   "metadata": {},
   "source": [
    "### Let's see which one is the fastest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit compute_l2_norm_along_last_axis_very_bad(A)\n",
    "%timeit compute_l2_norm_along_last_axis_bad(A)\n",
    "%timeit compute_l2_norm_along_last_axis_good(A)\n",
    "%timeit compute_l2_norm_along_last_axis_idiomatic(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fdb50",
   "metadata": {},
   "source": [
    "### \n",
    "### We have two clear winners in terms of readability and speed !\n",
    "### \n",
    "### When you use a `numpy` function like `np.linalg.norm`, there is usually\n",
    "### an `axis` argument which you can use to perform an operation along an axis.\n",
    "### \n",
    "### `Numpy` programming $\\neq$ `Python` programming.\n",
    "### If you know `Python` you don't automatically know how to use `Numpy`.\n",
    "### However, if you're really good at `Numpy` you're typically also really good at `Python`.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### We come back to our `derivative.py` code from the `OOP` lecture.\n",
    "### It's exactly the same code but now I allowed everything to be a vectorised\n",
    "### `Numpy` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load vector/derivative_vectorised.py\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Sequence, Tuple, Union, Any, Callable\n",
    "from abc import abstractmethod\n",
    "from collections.abc import Hashable\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - the entire code but vectorized \"\"\"\n",
    "NumericType = Union[int, float]\n",
    "FunctionType = Union['DifferentiableFunction', NumericType]\n",
    "\n",
    "\n",
    "\"\"\" [NEW] - supported input types to the `__call__` method \"\"\"\n",
    "CallInputType = NumericType | np.ndarray | Sequence[NumericType]\n",
    "\n",
    "\n",
    "def as_function(func: FunctionType) -> 'DifferentiableFunction':\n",
    "  if isinstance(func, DifferentiableFunction):\n",
    "    return func\n",
    "  return Constant(func)\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def _derivative(self: 'DifferentiableFunction') -> 'DifferentiableFunction':\n",
    "  return self._deriv()\n",
    "\n",
    "\n",
    "class DifferentiableFunction(Hashable):\n",
    "\n",
    "  def __init__(self, args: Sequence[Hashable]) -> None:\n",
    "    self._args = tuple(args)\n",
    "    self._hash = hash(self._args)\n",
    "\n",
    "  def __hash__(self) -> int:\n",
    "    return self._hash\n",
    "\n",
    "  def __eq__(self, other: Any) -> bool:\n",
    "    return self.__class__ == other.__class__ and hash(self) == hash(other) and self._args == other._args\n",
    "\n",
    "  @abstractmethod\n",
    "  def _deriv(self):\n",
    "    pass\n",
    "\n",
    "  \"\"\" [NEW] - replace type hint to accomodate also np.ndarray \"\"\"\n",
    "  @abstractmethod\n",
    "  def __call__(self, x: CallInputType) -> np.ndarray:\n",
    "    pass\n",
    "\n",
    "  def derivative(self, n: int = 1) -> 'DifferentiableFunction':\n",
    "    assert (n := int(n)) >= 0\n",
    "    if n == 0:\n",
    "      return self\n",
    "    # use the cached version.\n",
    "    return _derivative(self).derivative(n=n-1)\n",
    "\n",
    "  def plot(self, interval: Tuple[int, int] = (0, 1), npoints: int = 1001) -> None:\n",
    "    \"\"\" Plot function over the interval `interval` using `npoints` function evaluations. \"\"\"\n",
    "    a, b = interval\n",
    "    assert b > a\n",
    "    x = np.linspace(*interval, 1001)\n",
    "    y = self(x)\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "  def __add__(self, other: FunctionType) -> 'Add':\n",
    "    return Add(self, other)\n",
    "\n",
    "  __radd__ = __add__\n",
    "\n",
    "  def __mul__(self, other: FunctionType) -> 'Multiply':\n",
    "    return Multiply(self, other)\n",
    "\n",
    "  __rmul__ = __mul__\n",
    "\n",
    "  def __sub__(self, other: FunctionType) -> 'Add':\n",
    "    return self + (-1) * other\n",
    "\n",
    "  def __rsub__(self, other: NumericType) -> 'Add':\n",
    "    return other + (-1) * self\n",
    "\n",
    "\n",
    "class Constant(DifferentiableFunction):\n",
    "\n",
    "  def __init__(self, value: NumericType) -> None:\n",
    "    self.value = float(value)\n",
    "    super().__init__([self.value])\n",
    "\n",
    "  def _deriv(self) -> 'Constant':\n",
    "    return Constant(0)\n",
    "\n",
    "  def __call__(self, x: CallInputType) -> float:\n",
    "    return np.asarray(self.value)\n",
    "\n",
    "\n",
    "class Argument(DifferentiableFunction):\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__([])\n",
    "\n",
    "  def _deriv(self) -> Constant:\n",
    "    return Constant(1)\n",
    "\n",
    "  def __call__(self, x: CallInputType) -> np.ndarray:\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "\n",
    "class Add(DifferentiableFunction):\n",
    "\n",
    "  def __init__(self, f0: FunctionType, f1: FunctionType) -> None:\n",
    "    self.f0, self.f1 = sorted(map(as_function, (f0, f1)), key=lambda x: (x.__class__.__name__, hash(x)))\n",
    "    super().__init__([self.f0, self.f1])\n",
    "\n",
    "  def _deriv(self) -> 'Add':\n",
    "    return self.f0.derivative() + self.f1.derivative()\n",
    "\n",
    "  def __call__(self, x: CallInputType) -> np.ndarray:\n",
    "    return self.f0(x) + self.f1(x)\n",
    "\n",
    "\n",
    "class Multiply(DifferentiableFunction):\n",
    "\n",
    "  def __init__(self, f0: FunctionType, f1: FunctionType) -> None:\n",
    "    self.f0, self.f1 = sorted(map(as_function, (f0, f1)), key=lambda x: (x.__class__.__name__, hash(x)))\n",
    "    super().__init__([self.f0, self.f1])\n",
    "\n",
    "  def _deriv(self) -> Add:\n",
    "    return self.f0.derivative() * self.f1 + self.f0 * self.f1.derivative()\n",
    "\n",
    "  def __call__(self, x: CallInputType) -> np.ndarray:\n",
    "    return self.f0(x) * self.f1(x)\n",
    "\n",
    "\n",
    "class ChainRule(DifferentiableFunction):\n",
    "\n",
    "  evalf: Callable\n",
    "  df: Callable\n",
    "\n",
    "  def __init__(self, argument: FunctionType) -> None:\n",
    "    assert all(hasattr(self, item) for item in ('evalf', 'df')), 'Each derived class needs to implement `evalf` and `df`.'\n",
    "    self.argument = as_function(argument)\n",
    "    super().__init__([self.argument])\n",
    "\n",
    "  def _deriv(self) -> DifferentiableFunction:\n",
    "    return self.df(self.argument) * self.argument.derivative()\n",
    "\n",
    "  def __call__(self, x: CallInputType) -> np.ndarray:\n",
    "    return self.evalf(self.argument(x))\n",
    "\n",
    "\n",
    "class Exp(ChainRule):\n",
    "  evalf = np.exp\n",
    "  df = lambda self, argument: self\n",
    "\n",
    "\n",
    "class Sin(ChainRule):\n",
    "  evalf = np.sin\n",
    "  df = lambda self, argument: Cos(argument)\n",
    "\n",
    "\n",
    "class Cos(ChainRule):\n",
    "  evalf = np.cos\n",
    "  df = lambda self, argument: (-1) * Sin(argument)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] create a complex function \"\"\"\n",
    "\n",
    "# f = 25y + y' + y'' + y''' + y''''\n",
    "# with y = c0 * exp(-.5x) * sin(w0x) + c1 * exp(-.5x) * cos(w0x)\n",
    "\n",
    "# make an argument f(x) = x\n",
    "x = Argument()\n",
    "\n",
    "# choose some c0, c1\n",
    "c0, c1 = 2, 1\n",
    "\n",
    "# make the damping term\n",
    "exp = Exp(-.5 * x)\n",
    "\n",
    "# define the natural frequency\n",
    "w0 = 3 * np.sqrt(11) / 2\n",
    "\n",
    "# create y(x) using syntactic sugar\n",
    "y = c0 * exp * Sin(w0 * x) + c1 * exp * Cos(w0 * x)\n",
    "\n",
    "complex_func = 25 * y + y.derivative() + y.derivative(2) + y.derivative(3) + y.derivative(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02774fce",
   "metadata": {},
   "source": [
    "### \n",
    "### We time the vectorised and the non-vectorised versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5eaa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = np.linspace(0, 1, 1001)\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - do 1001 evaluations vectorized and in a for loop \"\"\"\n",
    "\n",
    "\n",
    "# for loop\n",
    "t0 = time.time()\n",
    "[complex_func(_xi) for _xi in xi]\n",
    "t1 = time.time()\n",
    "print(f\"for loop took {t1 - t0} seconds.\\n\")\n",
    "\n",
    "\n",
    "# vectorized\n",
    "t0 = time.time()\n",
    "complex_func(xi)\n",
    "t1 = time.time()\n",
    "print(f\"Vectorised operation took {t1 - t0} seconds.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6a80c",
   "metadata": {},
   "source": [
    "### \n",
    "### You don't really need custom compilation here. `Numpy` is fast enough for this task.\n",
    "\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "\n",
    "### In the following, a quick wrap-up of the basics of `numpy`. Since this is an _advanced_\n",
    "### `Python` course, I assume that everyone has some familiarity.\n",
    "### \n",
    "\n",
    "### The most important tool that `numpy` gives us is the `numpy.newaxis` variable which is\n",
    "### a convenient alias for `None`. For improved readability it is very common to set `_ = np.newaxis`. \n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_ = np.newaxis\n",
    "\n",
    "print(f\"_ == np.newaxis == None ? {_ == np.newaxis == None}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e94ee",
   "metadata": {},
   "source": [
    "### \n",
    "### The `_` variable allows us to create a new `artificial` axis, which creates an axis of\n",
    "### dimension `1` at the spot where we put it.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(2, 3)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - print various broadcast shapes \"\"\"\n",
    "print(f\"         A.shape:    {A.shape}.\\n\")\n",
    "print(f\"A[_, :, :].shape: {A[_].shape}.\\n\")\n",
    "print(f\"      A[_].shape: {A[_].shape} - trailing colons are inferred. \\n\")\n",
    "print(f\"   A[:, _].shape: {A[:, _].shape}.\\n\")\n",
    "print(f\"A[:, :, _].shape: {A[:, :, _].shape}.\\n\")\n",
    "print(f\" A[..., _].shape: {A[..., _].shape}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1c37b",
   "metadata": {},
   "source": [
    "### \n",
    "### Here the `Ellipsis` variable `...` _infers_ all remaining dimensions.\n",
    "\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### When we perform an operation between two `np.ndarray`'s of shape\n",
    "### `(n0, n1, ..., nM)` and\n",
    "### `(m0, m1, ..., mM)`\n",
    "### the output shape is: \n",
    "### `(max(n0, m0), max(n1, m1), ..., max(nM, mM))`. \n",
    "### If `ni != mi` then either `ni == 1` or `mi == 1` must hold.\n",
    "### \n",
    "### Let's suppose for now that there are no `1` axes. The following code\n",
    "### roughly reproduces a vectorised operation using some `np.ufunc`\n",
    "### (but is a trillion times slower):\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d364cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - do a np.ufunc operation in a for loop \"\"\"\n",
    "def numpy_equivalent_ufunc_operation(arr0: np.ndarray, arr1: np.ndarray, ufunc: np.ufunc) -> np.ndarray:\n",
    "    \n",
    "  assert arr0.shape == arr1.shape and 1 not in arr0.shape, NotImplementedError\n",
    "    \n",
    "  # we are also assuming that the data type is `float` for convenience\n",
    "  ret = np.empty(arr0.shape, dtype=float)\n",
    "  \n",
    "  # iterate over all combinations (i0, i1, i2, ...) from our shape\n",
    "  for multi_index in product(*map(range, arr0.shape)):\n",
    "    ret[multi_index] = ufunc(arr0[multi_index], arr1[multi_index])\n",
    "    \n",
    "  return ret\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "arr0 = np.random.randn(2, 3, 4)\n",
    "arr1 = np.random.randn(2, 3, 4)\n",
    "\n",
    "print(f\"np.add(arr0, arr1) is equal to our implementation ? {np.allclose(np.add(arr0, arr1), numpy_equivalent_ufunc_operation(arr0, arr1, np.add))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3785138",
   "metadata": {},
   "source": [
    "### \n",
    "### What changes when we DO allow for `1` axes ?\n",
    "### For an implementation, see below:\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from typing import Callable, Tuple\n",
    "from itertools import product\n",
    "\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - for allowing `1` axes \"\"\"\n",
    "def truncate_multi_index(multi_index: Tuple[int, ...], array_shape: Tuple[int, ...]) -> Tuple[int, ...]:\n",
    "  \"\"\"\n",
    "    index: (1, 2, 1, 4, 5), shape: (2, 3, 3, 6, 7) -> (1, 2, 1, 4, 5)\n",
    "    index: (1, 2, 1, 4, 5), shape: (2, 3, 3, 1, 1) -> (1, 2, 1, 0, 0)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    ETC\n",
    "  \"\"\"\n",
    "  return tuple( i if j != 1 else 0 for (i, j) in zip(multi_index, array_shape, strict=True) )\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - this time `1` axes are allowed \"\"\"\n",
    "def numpy_equivalent_ufunc_operation(arr0: np.ndarray, arr1: np.ndarray, ufunc: np.ufunc) -> np.ndarray:\n",
    "\n",
    "  # make sure the arrays are compatible\n",
    "  assert all( i == j or 1 in (i, j) for i, j in zip(arr0.shape, arr1.shape, strict=True) )\n",
    "\n",
    "  # output shape\n",
    "  shape = tuple(map(max, zip(arr0.shape, arr1.shape)))\n",
    "\n",
    "  # return array of dtype `float`\n",
    "  ret = np.empty(shape, dtype=float)\n",
    "  \n",
    "  # iterate over all combinations (i0, i1, i2, ...) from our shape\n",
    "  for multi_index in product(*map(range, shape)):\n",
    "    ret[multi_index] = ufunc( \n",
    "                              arr0[ truncate_multi_index(multi_index, arr0.shape) ],\n",
    "                              arr1[ truncate_multi_index(multi_index, arr1.shape) ]\n",
    "                            )\n",
    "    \n",
    "  return ret\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "arr0 = np.random.randn(2, 3, 4)[:, _]     # shape: (2, 1, 3, 4)\n",
    "arr1 = np.random.randn(2, 3, 4)[:, :, _]  # shape: (2, 3, 1, 4)\n",
    "\n",
    "print(f\"np.add(arr0, arr1) is equal to our implementation ? {np.allclose(np.add(arr0, arr1), numpy_equivalent_ufunc_operation(arr0, arr1, np.add))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7db13",
   "metadata": {},
   "source": [
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### Let `arr` of shape `(n0, ..., nN-1, nN, ..., nM)` be cast to \n",
    "###     `arr_` of shape `(n0, ..., nN-1, 1, nN, ..., nM)`.\n",
    "### \n",
    "### `Numpy` then broadcasts `arr_` such that\n",
    "### `arr_[i0, ..., iN-1, j, iN, ..., iM] == arr[i0, ..., iN-1, iN, ..., iM]`\n",
    "### for all `j` that are smaller than `pj` in the output shape `(..., pj, ...)`.\n",
    "### \n",
    "### When the dimension of the arrays we work with is small, it is helpful to visualize\n",
    "### things as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - create arrays \"\"\"\n",
    "arr0 = np.random.randn(3)\n",
    "arr1 = np.random.randn(5)\n",
    "\n",
    "outer_diff = arr0[:, _] - arr1[_, :]   # has shape (3, 5)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - use `broadcast_to` to see what the array is broadcast to. \"\"\"\n",
    "print(f\"arr0[:, _] is broadcast to: \\n\\n{np.broadcast_to(arr0[:, _], outer_diff.shape)}.\\n\")\n",
    "print(f\"arr1[_, :] is broadcast to: \\n\\n{np.broadcast_to(arr1[_, :], outer_diff.shape)}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ffbcf",
   "metadata": {},
   "source": [
    "### \n",
    "### When the number of dimensions is larger, it is better to think in terms of shapes.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "## <u> Exercise 1.1 </u>:\n",
    "### Given an array \n",
    "### `arr0` of shape `(p, n)` \n",
    "### and\n",
    "### `arr1` of shape `(q, n)`, \n",
    "### compute the matrix `dist` of shape `(p, q)` containing all Euclidean distances between the\n",
    "### row vectors of `arr0` and `arr1`. You're not allowed to use `np.linalg.norm` ;-)\n",
    "### \n",
    "### `dist[i, j]` = `|| arr0[i, :] - arr1[j, :] ||`.\n",
    "### \n",
    "\n",
    "### **HINT**:\n",
    "### `(p, n)`   and `(q, n)`    become\n",
    "### `(p, 1, n)` and `(1, q, n)` become \n",
    "### `(p, q, n)` and `(p, q, n)` becomes\n",
    "### `(p, q)`.\n",
    "### \n",
    "### <u>solution</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] \"\"\"\n",
    "p, q, n = 4, 6, 10\n",
    "\n",
    "arr0 = np.random.randn(p, n)\n",
    "arr1 = np.random.randn(q, n)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - all equivalent \"\"\"\n",
    "dist0 = ((arr0[:, _, :] - arr1[_, :, :])**2).sum(-1) ** .5\n",
    "\n",
    "# Numpy infers the trailing colons `:`.\n",
    "dist1 = ((arr0[:, _] - arr1[_])**2).sum(-1) ** .5\n",
    "\n",
    "# np.sqrt(x) is a tad faster than x ** .5 because it's optimised for square root only.\n",
    "dist2 = np.sqrt( ((arr0[:, _] - arr1[_])**2).sum(-1) )\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "print(f\"All are equivalent ? {np.allclose(dist0, dist1) and np.allclose(dist1, dist2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c041d9",
   "metadata": {},
   "source": [
    "### \n",
    "### Thinking in terms of shapes is no longer optional when the dimension of the\n",
    "### broadcast arrays exceeds $3$ (unless you came to visit us in our _flatland_ from a higher-dimensional universe).\n",
    "### \n",
    "### Luckily, this trick works in **the vast majority of cases** (and is therefore what I recommend you shoud do).\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### \n",
    "### We continue with another (preparational)\n",
    "## <u> Exercise 1.2 </u>:\n",
    "### Given arrays `arr0, arr1` of shape `(p, n)` and `(n, q)`, implement matrix multiplication\n",
    "### using vectorisation (don't use `@` or `np.matmul`).\n",
    "### \n",
    "### <u>solution</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82fe5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] \"\"\"\n",
    "p, q, n = 4, 6, 10\n",
    "\n",
    "arr0 = np.random.randn(p, n)\n",
    "arr1 = np.random.randn(n, q)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] \"\"\"\n",
    "# (p, n) and (n, q) becomes\n",
    "# (p, n, 1) and (1, n, q) becomes\n",
    "# (p, n, q) and (p, n, q) becomes\n",
    "# (p, q)\n",
    "\n",
    "# two equivalent ones\n",
    "matmul0 = (arr0[:, :, _] * arr1[_, :, :]).sum(1)\n",
    "matmul1 = (arr0[..., _] * arr1).sum(1)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "matmul = arr0 @ arr1\n",
    "print(f\"matmul0 and matmul1 are both equal to matmul0 @ matmul1 ? {np.allclose(matmul0, matmul) and np.allclose(matmul1, matmul)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a01827c",
   "metadata": {},
   "source": [
    "### \n",
    "### \n",
    "### \n",
    "### \n",
    "### \n",
    "### The big question is: why were we allowed to do `(arr0[..., _] * arr1)` ?\n",
    "### `arr0[..., _]` has three dimensions `(p, n, 1)` while `arr1` has two `(n, q)` ?!?\n",
    "### \n",
    "### $\\implies$ If one array is _shorter_ than the other, `Numpy` prepends as many `1` axes as necessary !\n",
    "### `(p, n, 1)` and `(n, q)` becomes `(p, n, 1)` and `(1, n, q)`.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### Now suppose you have an array of dimension `N` and you would like to add an artificial axis at the\n",
    "### `m`-th spot, with `m` < `N`. However you know `m` only at runtime. What do you do ?\n",
    "### \n",
    "### You have to somehow pass `m` colons `:` into the array brackets and then a new axis.\n",
    "### For instance, `arr.shape == (3, 4, 5, 6, 7, 2, 2)` and `m == 3`\n",
    "### $\\implies$ `arr[:, :, :, _].shape == (3, 4, 5, 1, 6, 7, 2, 2)`.\n",
    "### \n",
    "### Here is how you can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e647d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - this guy is equivalent to a colon `:` \"\"\"\n",
    "sl = slice(None)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - add new axis at `m`-th spot \"\"\"\n",
    "def add_axis_m(arr: np.ndarray, m: int) -> np.ndarray:\n",
    "    \n",
    "  # m colons plus a new axis =)\n",
    "  return arr[ (sl,) * m + (_,) ]\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "A = np.random.randn(3, 4, 5, 6, 7, 2, 2)\n",
    "\n",
    "print(f\"A has shape: {A.shape}.\\n\\n\")\n",
    "print(f\"Adding new axis to `A` at the 3rd spot gives shape: {add_axis_m(A, 3).shape}. \\n\\n\")\n",
    "print(f\"Adding new axis to `A` at the 5th spot gives shape: {add_axis_m(A, 5).shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae3ca3",
   "metadata": {},
   "source": [
    "### \n",
    "### Actually not that difficult ;-)\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### Now that we know how to multiply matrices using vectorisation and how to add axes in specific spots,\n",
    "### we will challenge ourselves a bit more.\n",
    "### \n",
    "## <u>Exercise 1.3</u>:\n",
    "### Given two arrays `arr0` and `arr1`, both of unknown dimension `N`.\n",
    "### Compute an array `matmul_m` that performs `matrix multiplication` along axes numbers `m` and `m+1`, with `m+1 < N`.\n",
    "### \n",
    "### I.e., `matmul_m` satisfies: \n",
    "### `//   matmul_m[i0, ..., i_(m-1),| :, :,| i_(m+2), ..., iN]`\n",
    "### `// =     arr0[    ...          | :, :,|          ...    ]`\n",
    "### `//     @ arr1[    ...          | :, :,|          ...    ]`.\n",
    "### This problem is solved by **thinking in terms of shapes !!**\n",
    "### \n",
    "### \n",
    "### <u>HINT</u>: here is what needs to happen (focus on the part between the `|   |`):\n",
    "### `(n0, ..., n_(m-1),| p, n,    | n_(m+2), ..., nN)` and \n",
    "### `(n0, ..., n_(m-1),|    n, q, | n_(m+2), ..., nN)` \n",
    "### becomes\n",
    "### `(    ...          | p, n, 1, |          ...    )` and \n",
    "### `(    ...          | 1, n, q, |          ...    )` \n",
    "### becomes\n",
    "### `(    ...          | p, n, q, |          ...    )` and \n",
    "### `(    ...          | p, n, q, |          ...    )` \n",
    "### becomes\n",
    "### `(n0, ..., n_(m-1),| p,    q, | n_(m+2), ..., nN)`.\n",
    "### \n",
    "### Compared to our previous implementation, there is a `head` and a `tail` we have to carry around.\n",
    "### \n",
    "### <u>Template</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] \"\"\"\n",
    "sl = slice(None)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - your code here \"\"\"\n",
    "def perform_matmul_m(arr0: np.ndarray,\n",
    "                     arr1: np.ndarray,\n",
    "                     m: int            ) -> np.ndarray:\n",
    "    \n",
    "  assert arr0.ndim == arr1.ndim and m + 1 < arr0.ndim\n",
    "    \n",
    "  return # ??? YOUR ONE-LINER HERE\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "\n",
    "# create two arrays and do matrix multiplication on axis m\n",
    "m = 3\n",
    "arr0 = np.random.randn(3, 4, 5, 6, 7, 2, 2)\n",
    "arr1 = np.random.randn(3, 4, 5, 7, 3, 2, 2)\n",
    "matmul_3 = perform_matmul_m(arr0, arr1, 3)\n",
    "\n",
    "\n",
    "# print result\n",
    "print(f\"                arr0 has shape: {arr0.shape}.\\n\")\n",
    "print(f\"                arr1 has shape: {arr1.shape}.\\n\")\n",
    "print(f\"matmul_m with m == 3 has shape: {matmul_3.shape}. \\n\\n\")\n",
    "\n",
    "\n",
    "# check if result is the same as with the numpy `@` operator\n",
    "multi_index = (0, 0, 0, sl, sl, 0, 0)\n",
    "print(f\"multi_index equals: {multi_index}.\\n\")\n",
    "\n",
    "print(f\"matmul_3[multi_index] equals arr0[multi_index] @ arr1[multi_index] ? {np.allclose(matmul_3[multi_index], arr0[multi_index] @ arr1[multi_index])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6af7f",
   "metadata": {},
   "source": [
    "### <u>solution</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7572ff1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] \"\"\"\n",
    "sl = slice(None)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - your code here \"\"\"\n",
    "def perform_matmul_m(arr0: np.ndarray,\n",
    "                     arr1: np.ndarray,\n",
    "                     m: int            ) -> np.ndarray:\n",
    "    \n",
    "  assert arr0.ndim == arr1.ndim and m + 1 < arr0.ndim\n",
    "    \n",
    "  # arr0[ (m + 2) colons and a new axis ]\n",
    "  # arr1[  m      colons and a new axis ]\n",
    "  return (arr0[ (sl,) * (m+2) + (_,)  ] * arr1[ (sl,) * m + (_,) ]).sum(m+1)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "\n",
    "# create two arrays and do matrix multiplication on axis m\n",
    "m = 3\n",
    "arr0 = np.random.randn(3, 4, 5, 6, 7, 2, 2)\n",
    "arr1 = np.random.randn(3, 4, 5, 7, 3, 2, 2)\n",
    "matmul_3 = perform_matmul_m(arr0, arr1, 3)\n",
    "\n",
    "\n",
    "# print result\n",
    "print(f\"                arr0 has shape: {arr0.shape}.\\n\")\n",
    "print(f\"                arr1 has shape: {arr1.shape}.\\n\")\n",
    "print(f\"matmul_m with m == 3 has shape: {matmul_3.shape}. \\n\\n\")\n",
    "\n",
    "\n",
    "# check if result is the same as with the numpy `@` operator\n",
    "multi_index = (0, 0, 0, sl, sl, 0, 0)\n",
    "print(f\"multi_index equals: {multi_index}.\\n\")\n",
    "\n",
    "print(f\"matmul_3[multi_index] equals arr0[multi_index] @ arr1[multi_index] ? {np.allclose(matmul_3[multi_index], arr0[multi_index] @ arr1[multi_index])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bc2c0",
   "metadata": {},
   "source": [
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### It is worth it to understand `Numpy` better. You'll be surprised by how much stuff\n",
    "### you can solve by making better use of `Numpy`.\n",
    "### \n",
    "## <u> Task </u>:\n",
    "### Given an array of arbitrary shape `(n0, ..., nM)`, write a function `normalize(arr)`\n",
    "### that normalizes `arr` along the last axis `in place` !\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - bad implementation \"\"\"\n",
    "def normalize_bad(arr: np.ndarray) -> None:\n",
    "  \n",
    "  # shape ( n0,  n1,  ...,  n_(N-1),   nN) becomes\n",
    "  # shape ( n0 x n1 x ... x n_(N-1),   nN)\n",
    "  arr = arr.reshape( (-1, arr.shape[-1]) )  # view into the same memory\n",
    "  \n",
    "  for i, subarr in enumerate(arr):\n",
    "    arr[i] /= np.linalg.norm(subarr, ord=2)\n",
    "    \n",
    "\n",
    "\"\"\" [FOCUS] - better \"\"\"\n",
    "def normalize_ok(arr: np.ndarray) -> None:\n",
    "  norm = np.linalg.norm(arr, ord=2, axis=-1)\n",
    "  arr[:] = arr / norm[..., _]\n",
    "  # here it would be better to say arr /= norm[..., _]\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - good \"\"\"\n",
    "def normalize_good(arr: np.ndarray) -> None:\n",
    "  np.divide(arr, np.linalg.norm(arr, ord=2, axis=-1, keepdims=True), out=arr)\n",
    "  \n",
    "  \n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "A = np.random.randn(4, 3, 2, 6, 10)\n",
    "\n",
    "A0 = A.copy()\n",
    "normalize_bad(A0)\n",
    "\n",
    "A1 = A.copy()\n",
    "normalize_ok(A1)\n",
    "\n",
    "A2 = A.copy()\n",
    "normalize_good(A2)\n",
    "\n",
    "print(f'All three implementations give the same value: {all(np.allclose(A0, Ai) for Ai in (A1, A2))}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit normalize_bad(A)\n",
    "%timeit normalize_ok(A)\n",
    "%timeit normalize_good(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56c91a",
   "metadata": {},
   "source": [
    "### \n",
    "### The last two implementations are an order of magnitude faster because they avoid the for loop.\n",
    "### \n",
    "### The third implementation is a tad faster than the second because:\n",
    "### 1. The line `arr[:] = arr / norm[..., _]` actually creates a new array `y := arr / norm[..., _]`\n",
    "### which is then copied back into `arr`.\n",
    "### 2. The broadcast `norm[..., _]` creates a slight overhead.\n",
    "### \n",
    "### In the last implementation, we avoided the broadcast by passing `keepdims=True` in the `np.linalg.norm`\n",
    "### function. Each function that performs an axis reduction has this keyword argument. It works as follows:\n",
    "### \n",
    "### `reduction_func(arr, axis=(2, 4, 5))`:\n",
    "### shape `(2, 3, 4, 2, 5, 6, 6)` becomes `(2, 3, 2, 6)`\n",
    "### \n",
    "### `reduction_func(arr, axis=(2, 4, 5), keepdims=True):`\n",
    "### shape `(2, 3, 4, 2, 5, 6, 6)` becomes `(2, 3, 1, 2, 1, 1, 6)`.\n",
    "\n",
    "### \n",
    "### The `keepdims=True` keyword is very helpful for vectorisation.\n",
    "### \n",
    "\n",
    "### More importantly: in the `np.divide` function we passed `out=arr` which avoids allocating new memory\n",
    "### but performs the operation into the existing array `arr` we passed.\n",
    "### \n",
    "\n",
    "### It is worth studying the the extra arguments of `np.ufunc`'s. \n",
    "### If you're struggling with something, you're probably not the first person to do so.\n",
    "### The guys at `numpy` try to address these issues and continuously add functionality that people need.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "\n",
    "### As a last topic on `Numpy`, we discuss `masked` arrays. Unless you work with stochastic processes\n",
    "### or statistical data, you won't need them often but it's nevertheless a nice gimmick.\n",
    "### \n",
    "## <u>Task</u>:\n",
    "### You're given an `N`-dimensional array and you would like to take the mean of that array along the\n",
    "### `n`-th (`n < N`) axis. However, you wanna remove all entries that are below a threshold `eps` and\n",
    "### not count them toward the mean.\n",
    "### \n",
    "### For instance, say that `N == 2` (matrix) and you wanna take the mean along the `n == 1` axis.\n",
    "### Since some rows may be thinned out more than others, you have to do this in a for-loop ...\n",
    "### (don't even try to understand all the details, it's futile ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "               \n",
    "\n",
    "\"\"\" Don't [FOCUS] too much, this function is a mess \"\"\"\n",
    "def mean_with_threshold(arr: np.ndarray,\n",
    "                        axis: int,\n",
    "                        eps: float       ) -> np.ndarray:\n",
    "\n",
    "  # Initialize an output array to hold the sum values and counts along the specified axis\n",
    "  shape = arr.shape[:axis] + arr.shape[axis+1:]\n",
    "  sums = np.zeros(shape, dtype=float)\n",
    "  counts = np.zeros(shape, dtype=int)\n",
    "    \n",
    "  # Iterate over all slices along the specified axis\n",
    "  for multi_index in product(*map(range, sums.shape)):\n",
    "    slice_selector = multi_index[:axis] + (slice(None),) + multi_index[axis:]\n",
    "    values = arr[slice_selector]\n",
    "\n",
    "    # Apply a boolean mask to filter values based on the threshold\n",
    "    filtered_values = values[values >= eps]\n",
    "\n",
    "    # Update the sums and counts based on the filtered values\n",
    "    if filtered_values.size > 0:\n",
    "      sums[multi_index] = np.sum(filtered_values)\n",
    "      counts[multi_index] = filtered_values.size\n",
    "    \n",
    "  # Compute the mean by dividing the sums by the counts (but only if the counts > 0)\n",
    "  return np.divide(sums, counts, where=(counts > 0))\n",
    "               \n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "A = np.random.randn(3, 5, 10, 7, 3, 4)\n",
    "\n",
    "print(f\"Mean alsong axis 2 equals masked mean along axis 2? {np.allclose(A.mean(axis=2), mean_with_threshold(A, 2, -0.02))} (to be expected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0f3ec",
   "metadata": {},
   "source": [
    "### \n",
    "### There is a laughably easy solution to the above.\n",
    "### The `np.ma.masked_array` allows you to pass a boolean mask `mask`\n",
    "### that is true where a value is **missing** (not where it is not missing).\n",
    "### Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [FOCUS] \"\"\"\n",
    "def masked_mean_with_threshold(arr: np.ndarray,\n",
    "                               axis: int,\n",
    "                               eps: float       ) -> np.ndarray:\n",
    "    \n",
    "  return np.ma.masked_array(arr, mask=arr < eps).mean(axis=axis) \\\n",
    "                                                .view(np.ndarray)  # convert back to normal array\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "print(f\"Both implementations give the same outclome?  {np.allclose(masked_mean_with_threshold(A, 2, -0.02), mean_with_threshold(A, 2, -0.02))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c90e51",
   "metadata": {},
   "source": [
    "### \n",
    "### Even though we already know the outcome, let's time the two implementations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802221d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_with_threshold(A, 2, -0.02)\n",
    "%timeit masked_mean_with_threshold(A, 2, -0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43760163",
   "metadata": {},
   "source": [
    "### \n",
    "### Not surprising ;-)\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "# <u> What we have learned: </u>\n",
    "### 1. Not using `numpy` vectorisation is a bad idea.\n",
    "### 2. Vectorisation becomes easier once we start thinking in terms of shapes.\n",
    "### 3. We can vectorise operations on arbitrarily-dimensional arrays using `Ellipsis` `...`\n",
    "### and passing a tuple containing `slice`'s and `np.newaxis`'s:\n",
    "### `arr[ (slice(None),) * m + (_,) ] ...`\n",
    "### 4. It is worth it to learn more about `np.ufunc` arguments, like `out=arr`.\n",
    "### 5. Missing data is conveniently handled using `np.ma.masked_array`.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "\n",
    "# <u>(Short) Lesson 2</u>:\n",
    "## Writing a parallelised `Python` code.\n",
    "### \n",
    "### By default a `Python` program runs largely on just one core.\n",
    "### There is a thing called the _Global Interpreter Lock_ which prevents more than one\n",
    "### process at a time to execute `Python` bytecode. \n",
    "### <u> **UPDATE** </u>: Python 3.13 introduces an experimental feature to disable the GIL.\n",
    "### \n",
    "### The GIL has been introduced and kept\n",
    "### for purposes of safety. It is against the philosophy of Python to allow for unsafe\n",
    "### operations. There are ongoing projects that work on a `Python` implementation that\n",
    "### allows for more daring parallelisation but, so far, none of them have really been successful.\n",
    "### The most successful project of this sort, so far, is `PyPy`. However, `PyPy` does not\n",
    "### support all `Numpy` features yet ...\n",
    "### \n",
    "### There is a way to parallelise `Python` code though. We can simply spawn several\n",
    "### `Python` interpreters, each with their own copy of the data. A downside is that the data\n",
    "### has to be copied.\n",
    "### (There is also a multi-threaded `Python` sort-of parallelisation but it is less useful in scientific computing).\n",
    "### \n",
    "### `Python` parallelisation is useful for non memory-bound tasks and since it spawns several\n",
    "### interpreters, writing a parallel `Python` code is easier and safer than in most languages.\n",
    "### \n",
    "## <u>Task </u>:\n",
    "### Given a regular grid over, say, $[0, 1]$, and a sufficiently regular function $f$,\n",
    "### write a parallelised code that integrates the function over the grid using Gaussian integration.\n",
    "### We can do this, for instance using `concurrent.futures`.\n",
    "### <u>Code</u>: (not vectorised for educational purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aeabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load parallel/quad.py\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from concurrent import futures\n",
    "from typing import Callable\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - THIS PART IS NOT SO IMPORTANT \"\"\"\n",
    "\n",
    "def integrate_sequential(f, nelems, order):\n",
    "  x = np.linspace(0, 1, nelems + 1)\n",
    "  grid = np.stack([x[:-1], x[1:]], axis=1)\n",
    "  points, weights = np.polynomial.legendre.leggauss(order)\n",
    "  points = (points + 1) / 2\n",
    "  weights = weights / 2\n",
    "\n",
    "  result = 0.0\n",
    "  for a, b in grid:\n",
    "    result += (b - a) * (weights * f((b - a) * points + a)).sum()\n",
    "  return result\n",
    "\n",
    "\n",
    "# Sequential function that is used for parallel execution\n",
    "def integrate_subgrid(args):\n",
    "  f, grid, order, fargs = args  # unpack all arguments. Note that fargs is passed to f\n",
    "  points, weights = np.polynomial.legendre.leggauss(order)\n",
    "  points = (points + 1) / 2\n",
    "  weights = weights / 2\n",
    "\n",
    "  result = 0.0\n",
    "  for a, b in grid:\n",
    "    result += (b - a) * (weights * f((b - a) * points + a, *fargs)).sum()\n",
    "  return result\n",
    "\n",
    "\"\"\" [/HELPER] \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] ON THIS PART \"\"\"\n",
    "\n",
    "# Parallel integration using ProcessPoolExecutor\n",
    "def integrate_parallel(f: Callable, fargs, nelems: int, nprocs=4, order=3):\n",
    "  \"\"\"\n",
    "    Parallel version of the sequential implementation from above.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f: positional argument only function to integrate, of the form f(x, *fargs)\n",
    "    fargs: additional positional arguments passed to f, i.e., f(x, *fargs)\n",
    "    nelems: number of elements to divide [0, 1] into\n",
    "    nprocs: maximum number of parallel processes\n",
    "    order: gaussian integration order\n",
    "  \"\"\"\n",
    "  x = np.linspace(0, 1, nelems + 1)\n",
    "  grid = np.stack([x[:-1], x[1:]], axis=1)  # [[a0, a1], [a1, a2], ...]\n",
    "\n",
    "  # Split grid into roughly equal-sized subgrids for parallel processing\n",
    "  subgrids = np.array_split(grid, nprocs, axis=0)\n",
    "\n",
    "  args = [(f, subgrid, order, fargs) for subgrid in subgrids]\n",
    "\n",
    "  # compute partial integrals in parallel\n",
    "  with futures.ProcessPoolExecutor(max_workers=nprocs) as executor:\n",
    "    results = list(executor.map(integrate_subgrid, args))\n",
    "\n",
    "  return sum(results)  # sum sequentially\n",
    "\n",
    "\"\"\" [/FOCUS] \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - function to integrate \"\"\"\n",
    "def f(x, w):\n",
    "  return np.sin(w * x)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "def main(nelems=100000, order=3, nprocs=4):\n",
    "  w = 18 * np.pi\n",
    "\n",
    "  # keep track of computational times\n",
    "  t0 = time.time()\n",
    "  result_seq = integrate_sequential(lambda x: f(x, w=w), nelems, order)\n",
    "  t1 = time.time()\n",
    "  result_par = integrate_parallel(f, (w,), nelems, nprocs=nprocs, order=order)\n",
    "  t2 = time.time()\n",
    "\n",
    "  print(f\"The sequential implementation took {t1 - t0} seconds.\\n\\n\")\n",
    "  print(f\"The parallel implementation took {t2 - t1} seconds.\\n\\n\")\n",
    "  print(\"Parallelisation gives a speedup by a factor of \\033[4m{}\\033[0m. \\n\\n\".format((t1 - t0) / (t2 - t1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b06fd",
   "metadata": {},
   "source": [
    "### \n",
    "### Jupyter Notebook can't run parallel code from a cell (in Windows and MacOs) so we have to import from the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb11d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel.quad import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5992c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FOCUS] -  Run the main function from above for various grid densities \"\"\"\n",
    "\n",
    "nprocs = 6\n",
    "print(f\"nprocs = {nprocs} so we expect a maximum speedup of {nprocs}. \\n\\n\")\n",
    "print(\"\\n--------------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "for power in (3, 4, 5, 6, 7):  # the last one's gonna take a while.\n",
    "  nelems = 10 ** power\n",
    "  print(f\"Running the sequential and parallel versions for {nelems} elements.\\n\\n\")\n",
    "  main(nelems=int(10 ** power), nprocs=nprocs)\n",
    "  print(\"\\n--------------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f97cd",
   "metadata": {},
   "source": [
    "### \n",
    "### We conclude that it takes a particular problem size before parallelisation becomes worth it.\n",
    "### This is because spawning a process (with its own data) is itself costly.\n",
    "### \n",
    "### The biggest (coding) challenge of `Python` parallelisation is that all functions have to be \n",
    "### defined in the `global scope` of the script, i.e., the scope with zero indentation.\n",
    "### \n",
    "### Writing a code that allows you to create the function you wanna work with at runtime requires\n",
    "### extensive use of combining pre-defined functions via compositions and argument forwarding.\n",
    "### \n",
    "### It is possible but generally less readable and requires more careful planning.\n",
    "### Use it with care and make sure it is actually worth the extra work.\n",
    "### \n",
    "## <u>Exercise 2.1</u>:\n",
    "### Vectorise above code\n",
    "### \n",
    "### <u>Template</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - your code here \"\"\"\n",
    "def integrate_vectorised(f, nelems, order):\n",
    "  x = np.linspace(0, 1, nelems + 1)\n",
    "  points, weights = np.polynomial.legendre.leggauss(order)\n",
    "  points = (points + 1) / 2\n",
    "  weights = weights / 2\n",
    "  \n",
    "  a, b = x[:-1], x[1:]\n",
    "\n",
    "  return # YOUR ONE-LINER HERE\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - create function to be integrated \"\"\"\n",
    "f = lambda x: np.sin(18 * np.pi * x)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - Run the vectorised function for several input element sizes \"\"\"\n",
    "for power in (3, 4, 5, 6, 7):\n",
    "  nelems = 10 ** power\n",
    "  t0 = time.time()\n",
    "  integrate_vectorised(f, nelems, 3)\n",
    "  t1 = time.time()\n",
    "  print(f\"The vectorised operation with {nelems} elements took {t1 - t0} seconds.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbfca7",
   "metadata": {},
   "source": [
    "### \n",
    "### <u>solution</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9930f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "_ = np.newaxis\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - your code here \"\"\"\n",
    "def integrate_vectorised(f, nelems, order):\n",
    "  x = np.linspace(0, 1, nelems + 1)\n",
    "  points, weights = np.polynomial.legendre.leggauss(order)\n",
    "  points = (points + 1) / 2\n",
    "  weights = weights / 2\n",
    "  \n",
    "  a, b = x[:-1], x[1:]\n",
    "\n",
    "  return ((b - a)[:, _] * weights * f( (b - a)[:, _] * points + a[:, _] )).sum()\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - create function to be integrated \"\"\"\n",
    "f = lambda x: np.sin(18 * np.pi * x)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - Run the vectorised function for several input element sizes \"\"\"\n",
    "for power in (3, 4, 5, 6, 7):\n",
    "  nelems = 10 ** power\n",
    "  t0 = time.time()\n",
    "  integrate_vectorised(f, nelems, 3)\n",
    "  t1 = time.time()\n",
    "  print(f\"The vectorised operation with {nelems} elements took {t1 - t0} seconds.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912dcbfa",
   "metadata": {},
   "source": [
    "### \n",
    "### To underline again the importance of vectorisation ...\n",
    "### \n",
    "### Of course, a vectorised code like the one from exercise 2.1 can also be paralellised.\n",
    "### In that case, we would split the vectorised operations into batches.\n",
    "### \n",
    "### There is a library that simplifies this, called `Dask`. Check it out in case you're interested.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "# <u>Lesson 3</u>:\n",
    "## Using `Numba` for `JIT compilation`.\n",
    "### \n",
    "### We have seen how we can use `Numpy` vectorisation and `Python` parallelisation for considerable\n",
    "### speedups. However, sometimes it's just not good enough. For this, since $2012$, there has been \n",
    "### a `JIT` (just in time) compiler called `Numba`.\n",
    "### \n",
    "### The strengths of `Numba` are:\n",
    "### 1. You write `Numba` functions directly in your `Python` script, no separate `Numba` scripts needed.\n",
    "### 2. You write a normal `Python` function and decorate it as a `Numba` function, that's it.\n",
    "### You don't really need to learn anything new for it.\n",
    "### 3. It compiles to blazing fast machine code via `LLVM`, directly accessible from your `Python` implementation.\n",
    "### 4. It supports `embarassing parallelisation` using `prange` instead of `range`.\n",
    "### \n",
    "### The weaknesses:\n",
    "### 1. Not all valid `Python` code is also valid `Numba` code.\n",
    "### 2. If you want to write a complex `Python` program in pure `Numba`, you'll soon run into its limitations.\n",
    "### 3. It's much trickier to generalise operations to arbitrary dimension, especially when for-loops are needed.\n",
    "\n",
    "### \n",
    "### `Numba` is best for writing relatively small functions that perform an operation that cannot be\n",
    "### vectorised or for which vectorisation runs into memory issues.\n",
    "### \n",
    "### We come back to our `Numpy` implementation of the mesh union code from the first Lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - create and plot meshes \"\"\"\n",
    "\n",
    "def plot_meshes(list_of_elements, list_of_points, title=None):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for elems, points in zip(list_of_elements, list_of_points):\n",
    "        ax.triplot(*points.T, elems, alpha=0.5)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_mesh(nx: int, ny: int, translate=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"\n",
    "    Create a regular triangular mesh over [0, 1] x [0, 1].\n",
    "    Can optionally be translated by a vector `translate`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nx: number of mesh vertices in x-direction\n",
    "    ny: number of mesh vertices in y-direction\n",
    "    translate: (optional) translation vector.\n",
    "  \"\"\"\n",
    "  \n",
    "  points = np.stack(list(map(np.ravel, np.meshgrid(np.linspace(0, 1, nx),\n",
    "                                                   np.linspace(0, 1, ny) ))), axis=1)    \n",
    "  \n",
    "  if translate is not None:\n",
    "    points += np.asarray(translate)[None]\n",
    "    \n",
    "  points = np.round(points, 8)\n",
    "\n",
    "  \n",
    "  indices = (np.arange(nx * ny).reshape(ny, nx)[:-1, :-1]).ravel()\n",
    "  quads = np.stack([indices, indices+1, indices+ny+1, indices+ny], axis=1)\n",
    "  elements = quads[:, [0, 1, 2, 0, 2, 3]].reshape(-1, 3)\n",
    "  return elements, points\n",
    "\n",
    "\"\"\" [/HELPER] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [FOCUS] - pure Python implementation for mesh union \"\"\"\n",
    "def take_mesh_union_numpy(elems0, points0, elems1, points1):\n",
    "  \"\"\"\n",
    "    Take the unions of two meshes using only Python and Numpy\n",
    "    functionality.\n",
    "  \"\"\"\n",
    "    \n",
    "  # get all unique points of both meshes (vectorized = fast)\n",
    "  new_points = np.unique(np.concatenate([points0, points1]), axis=0)\n",
    "  \n",
    "  \n",
    "  \"\"\" [FOCUS] - These two operations require a pure Python for loop and cannot be vectorized \"\"\"\n",
    "\n",
    "  # map each unique point to an index\n",
    "  map_point_index = dict(zip(map(tuple, new_points), count()))\n",
    "\n",
    "  # map both meshes' elements' points to the new index\n",
    "  mapped_elems = np.apply_along_axis(lambda x: map_point_index[tuple(x)],\n",
    "                                     axis=-1,\n",
    "                                     arr=np.concatenate([points0[elems0], points1[elems1]]))\n",
    "  \n",
    "  \"\"\" [/FOCUS] \"\"\"\n",
    "\n",
    "  # find the indices of the first occurence of the transformed elements that are unique (vectorized)\n",
    "  _, unique_indices = np.unique(np.sort(mapped_elems, axis=1), return_index=True, axis=0)\n",
    "\n",
    "  # keep only the unique occurences (vectorized)\n",
    "  new_elems = mapped_elems[unique_indices]\n",
    "\n",
    "  return new_elems, new_points\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate \"\"\"\n",
    "elems0, points0 = create_mesh(51, 51)\n",
    "elems1, points1 = create_mesh(51, 51, translate=[0.5, 0])\n",
    "\n",
    "plot_meshes([elems0, elems1], [points0, points1], title=\"The two separate meshes\")\n",
    "\n",
    "elems_np, points_np = take_mesh_union_numpy(elems0, points0, elems1, points1)\n",
    "plot_meshes([elems_np], [points_np], title=\"The mesh union\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cc9ef",
   "metadata": {},
   "source": [
    "### \n",
    "### The `Numpy` implementation is obviously bottlenecked by the operation\n",
    "### that involves the `hashmap`. \n",
    "### \n",
    "### We may outsource this step to a `Numba` routine.\n",
    "### Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - the numba equivalent of `map_point_index = dict(zip(map(tuple, new_points), count()))` \"\"\"\n",
    "@njit(cache=True)\n",
    "def make_numba_indexmap(points):\n",
    "  \"\"\"\n",
    "    Create a hashmap that maps each point in `points` to a unique running index.\n",
    "    Assumes the points in `points` to already be unique.\n",
    "  \"\"\"\n",
    "  map_coord_index = {}\n",
    "  i = 0\n",
    "    \n",
    "  for point in points:\n",
    "    # we cannot say map_coord_index[ tuple(point) ] in a numba environment\n",
    "    map_coord_index[ (point[0], point[1]) ] = i\n",
    "    i += 1\n",
    "\n",
    "  return map_coord_index\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - renumber the `elements` array based on the new point indices \"\"\"\n",
    "@njit(cache=True)\n",
    "def renumber_elements_from_indexmap(elements, points, map_coord_index):\n",
    "  \"\"\"\n",
    "    Given a 2D array whose rows represent element,\n",
    "    a 2D array of points and a map that maps each point in \n",
    "    `points` to a unique index, renumber the elements using the\n",
    "    indexmap.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elements: element array to renumber\n",
    "    points: 2D element vertex coordinates\n",
    "    map_cord_index: hashmap mapping a tuple of coordinates to a\n",
    "                    unique index.\n",
    "  \"\"\"\n",
    "  newelems = np.empty(elements.shape, dtype=np.int64)\n",
    "  \n",
    "  for i in range(len(elements)):\n",
    "    \n",
    "    myvertices = elements[i]\n",
    "    for j, point in enumerate(points[myvertices]):\n",
    "      newelems[i, j] = map_coord_index[ (point[0], point[1]) ]\n",
    "      \n",
    "  return newelems\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Numba adjusted version \"\"\"\n",
    "def take_mesh_union_numba(elems0, points0, elems1, points1):\n",
    "  \"\"\"\n",
    "    Take the union of two meshes using Numpy and Numba functionality.\n",
    "  \"\"\"\n",
    "    \n",
    "  # vectorized so we don't use Numba here\n",
    "  new_points = np.unique(np.concatenate([points0, points1]), axis=0)\n",
    "  \n",
    "  \n",
    "  \"\"\" [FOCUS] - we now use Numba in the non-vectorized part \"\"\"\n",
    "\n",
    "  # map each unique point to an index in Numba\n",
    "  map_point_index = make_numba_indexmap(new_points)\n",
    "\n",
    "  # renumber both meshes' elements in numba and combine both resulting arrays into one array  \n",
    "  mapped_elems = \\\n",
    "    np.concatenate([ \n",
    "                      renumber_elements_from_indexmap(myelems, mypoints, map_point_index)\n",
    "                      for myelems, mypoints in zip([elems0, elems1], [points0, points1]) \n",
    "                   ])\n",
    "\n",
    "  \"\"\" [/FOCUS] - the rest is the same \"\"\"\n",
    "\n",
    "  # same as before\n",
    "  _, unique_indices = np.unique(np.sort(mapped_elems, axis=1), return_index=True, axis=0)\n",
    "  new_elems = mapped_elems[unique_indices]\n",
    "\n",
    "  return new_elems, new_points\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - validate, is it the same as the Python implementation ? \"\"\"\n",
    "elems0, points0 = create_mesh(51, 51)\n",
    "elems1, points1 = create_mesh(51, 51, translate=[0.5, 0])\n",
    "\n",
    "elems_nb, points_nb = take_mesh_union_numba(elems0, points0, elems1, points1)\n",
    "\n",
    "print(f\"Numpy and numba produce the same mesh union ? {(elems_nb == elems_np).all()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d922b13",
   "metadata": {},
   "source": [
    "### \n",
    "### We make a big mesh and time both implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [STEUP] - create two very big meshes \"\"\"\n",
    "elems0, points0 = create_mesh(101, 101)\n",
    "elems1, points1 = create_mesh(101, 101, translate=[0.5, 0])\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - compare the comp. times \"\"\"\n",
    "%timeit take_mesh_union_numpy(elems0, points0, elems1, points1)\n",
    "%timeit take_mesh_union_numba(elems0, points0, elems1, points1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b78ad",
   "metadata": {},
   "source": [
    "### \n",
    "### Quite an impressive speedup just by jitting away the hashmap !\n",
    "### \n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### `Numba` is perfect for taking a pure `Python / Numpy` code, identifying\n",
    "### performance bottlenecks and jitting them away. It's important to write\n",
    "### a `modular` code consisting of many puzzle pieces.\n",
    "### \n",
    "### Do not expect any performance gains from jitting away single `Numpy`\n",
    "### functions. In fact, `Numpy` is so well optimised that the `Numba`\n",
    "### equivalent tends to be a tad slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - numpy and numba sin function \"\"\"\n",
    "sin_numpy = np.sin\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def sin_numba(x):\n",
    "  return np.sin(x)\n",
    "\n",
    "x = np.linspace(0, 1, 1001)\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - run once to compile \"\"\"\n",
    "sin_numba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [HELPER] - time both versions \"\"\"\n",
    "%timeit sin_numpy(x)\n",
    "%timeit sin_numba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ddfbeb",
   "metadata": {},
   "source": [
    "### \n",
    "### Performance gains can be expected when `Numpy` vectorisation is not\n",
    "### (100%) possible. \n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### <u>Task </u>:\n",
    "### You have an `np.arange` of `N` increasing indices representing degrees\n",
    "### of freedom in a FEM basis (or whatever). \n",
    "### You are given an integer array of pairs that you're coupling (each fusing 2 DOFs in one).\n",
    "### Modify the DOF array inplace to always point to the lower of the two DOFs you're coupling.\n",
    "### Then renumber the dofs in ascending order.\n",
    "### \n",
    "### Example:\n",
    "### `N == 5`, `dofs = [0, 1, 2, 3, 4]`, `pairs = [ [1, 2], [0, 1], [3, 4] ]`\n",
    "### couple: `dofs = [0, 0, 0, 3, 3]`\n",
    "### renumber: `dofs = [0, 0, 0, 1, 1]`\n",
    "### \n",
    "### One implementation in pure `Numpy` and one using `Numba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - I don't know how to vectorise this one \"\"\"\n",
    "def _apply_pairs(dofs: np.ndarray,\n",
    "                 pairs: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "  while True:                          # apply pairs until `dofs` no longer changes\n",
    "    dofs_old = dofs.copy()             # keep track of old dof vector\n",
    "    \n",
    "    for pair in pairs:                 # python for loop ...\n",
    "      dofs[pair] = np.min(dofs[pair])\n",
    "        \n",
    "    if (dofs_old == dofs).all():       # old and new dof vector the same ? => we're done\n",
    "      return dofs\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - renumber in Python \"\"\"\n",
    "def renumber_np(ndofs: int, pairs: np.ndarray) -> np.ndarray:\n",
    "  dofs = np.arange(ndofs)\n",
    "  dofs = _apply_pairs(dofs, pairs)\n",
    "  \n",
    "  return np.unique(dofs, return_inverse=True)[1]\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Numba version is the same, just with the numba decorator \"\"\"\n",
    "@njit(cache=True)\n",
    "def _apply_pairs_nb(dofs, pairs):\n",
    "  \n",
    "  while True:\n",
    "    dofs_old = dofs.copy()\n",
    "    \n",
    "    for pair in pairs:\n",
    "      dofs[pair] = np.min(dofs[pair])\n",
    "        \n",
    "    if (dofs_old == dofs).all():\n",
    "      return dofs\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - reNumba \"\"\"\n",
    "def renumber_nb(ndofs: int, pairs: np.ndarray) -> np.ndarray:\n",
    "  dofs = np.arange(ndofs)\n",
    "  dofs = _apply_pairs_nb(dofs, pairs)\n",
    "  \n",
    "  return np.unique(dofs, return_inverse=True)[1]\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - first check if we reproduce the example \"\"\"\n",
    "pairs = np.array([[1, 2], [0, 1], [3, 4]])\n",
    "print(f\"Passing the data from the example gives: {renumber_np(5, pairs)}. \\n\\n\\n\")\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - create random pairs \"\"\"\n",
    "ndofs = 1_000_000\n",
    "npairs = 200_000\n",
    "\n",
    "pairs = np.unique(np.random.randint(0, ndofs, (npairs, 2)), axis=1)  \n",
    "pairs = pairs[ pairs[:, 0] != pairs[:, 1] ]  # remove pairs of the form [a, b] with a == b\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - do numba and python give the same outcomes? \"\"\"\n",
    "print(f\"Numpy and numba give the same outcomes? {(renumber_np(ndofs, pairs) == renumber_nb(ndofs, pairs)).all()}. \\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a666807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [HELPER] - compare the comp. times \"\"\"\n",
    "%timeit renumber_np(ndofs, pairs)\n",
    "%timeit renumber_nb(ndofs, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108757cd",
   "metadata": {},
   "source": [
    "### \n",
    "### A `20x` speedup (on my machine) just by jitting the `_apply_pairs` function.\n",
    "### \n",
    "### Another application of `Numba` is jitting `Numpy` vectorisable functions \n",
    "### that would run into memory issues for big inputs. We can also often parallelise\n",
    "### such operations using `embarassing parallelisation`.\n",
    "### \n",
    "### Let's check out again our vectorised implementation of the integrate function\n",
    "### from lesson one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load numba/integrate.py\n",
    "\"\"\" [IMPORT] - njit and prange (parallel range) \"\"\"\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "import time\n",
    "\n",
    "_ = np.newaxis\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - number of processes to use \"\"\"\n",
    "NPROCS = 6\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Parallel and sequential integration of a function over a mesh \"\"\"\n",
    "@njit(cache=True, parallel=True, fastmath=True)\n",
    "def _integrate_numba_parallel(f, nelems, weights, points):\n",
    "  \"\"\"\n",
    "    We have to pass weights and points because\n",
    "    np.polynomial.legendre.leggaus is not available\n",
    "    inside of a Numba function.\n",
    "    We can however pass Numba jitted functions `f` as arguments.\n",
    "  \"\"\"\n",
    "  ret = np.empty((NPROCS,), dtype=np.float64)\n",
    "  batch_size = nelems // NPROCS\n",
    "\n",
    "  # run in parallel\n",
    "  for i in prange(NPROCS):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size if i != (NPROCS-1) else nelems\n",
    "\n",
    "    val = 0.0\n",
    "    for j in range(start, end):\n",
    "      a, b = j / nelems, (j+1) / nelems\n",
    "\n",
    "      for k in range(len(weights)):\n",
    "        val += (b - a) * weights[k] * f((b - a) * points[k] + a)\n",
    "\n",
    "    ret[i] = val\n",
    "\n",
    "  return ret.sum()  # sum sequentially\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def _integrate_numba_sequential(f, nelems, weights, points):\n",
    "  \"\"\"\n",
    "    Same as above but sequential\n",
    "  \"\"\"\n",
    "  val = 0.0\n",
    "  for j in range(0, nelems):\n",
    "    a, b = j / nelems, (j+1) / nelems\n",
    "\n",
    "    for k in range(len(weights)):\n",
    "      val += (b - a) * weights[k] * f((b - a) * points[k] + a)\n",
    "\n",
    "  return val\n",
    "\n",
    "\n",
    "# function we gonna integrate\n",
    "@njit(cache=True)\n",
    "def _sin(x):\n",
    " return np.sin(18 * np.pi * x)\n",
    "\n",
    " \"\"\" [/FOCUS] \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - Python function that calls sequential or parallel Numba integration \"\"\"\n",
    "def integrate_numba(f, nelems, order, parallel=True):\n",
    "  points, weights = np.polynomial.legendre.leggauss(order)\n",
    "  points = (points + 1) / 2\n",
    "  weights = weights / 2\n",
    "  return {True: _integrate_numba_parallel,\n",
    "          False: _integrate_numba_sequential}[parallel](f, nelems, weights, points)\n",
    "\n",
    "\n",
    "print(f\"Sequential and parallel outcome is the same ? {np.allclose(integrate_numba(_sin, 10, 3, parallel=False), integrate_numba(_sin, 10, 3, parallel=True))}\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - time sequential and parallel implementations for various mesh sizes \"\"\"\n",
    "\n",
    "# sequential\n",
    "for power in (2, 3, 5, 6, 7, 8):\n",
    "  nelems = 10 ** power\n",
    "  t0 = time.time()\n",
    "  integrate_numba(_sin, nelems, 3, parallel=False)\n",
    "  t1 = time.time()\n",
    "  print(f\"The sequential Numba implementation with {nelems} elements took {t1 - t0} seconds.\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n-----------------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "# parallel\n",
    "for power in (2, 3, 5, 6, 7, 8):\n",
    "  nelems = 10 ** power\n",
    "  t0 = time.time()\n",
    "  integrate_numba(_sin, nelems, 3, parallel=True)\n",
    "  t1 = time.time()\n",
    "  print(f\"The parallel Numba implementation with {nelems} elements took {t1 - t0} seconds.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de7a3b",
   "metadata": {},
   "source": [
    "### \n",
    "### A little code from my PhD (I was inexperienced compared to now, so it's not the best code).\n",
    "### \n",
    "<img src=\"img/jitted_phd_code.png\" alt=\"Drawing\" width=\"700\"/>\n",
    "\n",
    "### \n",
    "### The entire scipt is $1600$ lines of code. Jitting just these two functions\n",
    "### (and two more small auxiliary functions) sped up my code by a factor of $12$ !\n",
    "### \n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5e31f",
   "metadata": {},
   "source": [
    "# <u> What we have learned: </u>\n",
    "### 1. Writing `Numba` functions is relatively easy if we already know `Python`.\n",
    "### 2. Identifying performance bottlenecks and writing small jitted functions can be a highly effective strategy.\n",
    "### 3. While gaining performance, we give up some flexibility, `tuple(point) -> (point[0], point[1])`.\n",
    "### \n",
    "### If you do things related to optimisation, I can recommend `JAX`.\n",
    "### It's similar to `Numba` but can also differentiate your code for computing gradients.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21beaa89",
   "metadata": {},
   "source": [
    "# <u>Lesson 4</u>:\n",
    "## Pimping your code with `Cython`.\n",
    "### \n",
    "### `Numba` is dope but my experience is that at some point, it will simply not be enough.\n",
    "### \n",
    "### In case you need better performance but the restrictions of `Numba` (such as \n",
    "### rudimentary support for classes, structs and enums) prevent you from\n",
    "### really getting the job done, the next thing you should try is `Cython`.\n",
    "### \n",
    "### The standard `Python` interpreter is written in `C`. What `Cython` does is, it \n",
    "### has you write code in a `Python`-ish language and translates it to a `C` file (you can actually see it).\n",
    "### Then, in the `C` program, for all things that are known at compile time, it writes a `C` function\n",
    "### and for the remaining stuff, it invokes the `Python` interpreter from the `C` file.\n",
    "### \n",
    "### Here are some of `Cython`'s strengths:\n",
    "### 1. 99.9% of valid `Python` code is also valid `Cython` code.\n",
    "### 2. You don't have to write everything in `C` style. Some parts of your code you want to and can keep interpreted.\n",
    "### 3. Calling the compiled `Cython` functionality from pure `Python` is a piece of cake.\n",
    "### 4. It supports classes, structs but also things like enums.\n",
    "### \n",
    "### Here some weaknesses:\n",
    "### 1. `Cython` is `ahead of time` rather than `JIT` compiled.\n",
    "### 2. It requires learning a new, albeit very similar, language to unlock all performance features.\n",
    "### 3. If you really want a super performant and parallelised code, you're closer to the rather\n",
    "### unsafe `C` coding style than in `Numba` and you have to give up more `Numpy` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4dae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517866e",
   "metadata": {},
   "source": [
    "### \n",
    "### `Cython` allows you to staticly type variables, significantly reducing the \n",
    "### `Python` type checking overhead. This can make a tremendous difference in\n",
    "### performance. Let's assume we're bad at numpy vectorisation and just wanna\n",
    "### create a list of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca668b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - square integers in Python \"\"\"\n",
    "def squares_py(nsquares: int) -> List[int]:\n",
    "  return [i**2 for i in range(nsquares)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c3348-1929-4986-a781-8bc22c4cca21",
   "metadata": {},
   "source": [
    "### We can use `Cython` to type declare all variables used within the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1e195-f7ab-462d-9ed2-c3a8a6e76845",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\n",
    "# cdef = can only be used from a cython environment\n",
    "# cpdef = can be used both from cython and python\n",
    "# def  = only python\n",
    "\n",
    "\"\"\" [FOCUS] - we declare all types used in the function \"\"\"\n",
    "cpdef list[int] squares_cy(int nsquares):\n",
    "  cdef int i, j = 2\n",
    "  cdef list result = []\n",
    "    \n",
    "  for i in range(nsquares):\n",
    "    result.append(i ** j)\n",
    "    \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d14f6-f257-449d-a356-f7a05b4d21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit squares_py(50000)\n",
    "%timeit squares_cy(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f38e96",
   "metadata": {},
   "source": [
    "### Already quite a speedup for a simple type declaration.\n",
    "### \n",
    "### We can further speed up by interacting with `list` directly from the `C` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "from cpython.list cimport PyList_New, PyList_SET_ITEM\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - square integers in Cython, we are interacting with the `PyObject` list directly from C \"\"\"\n",
    "cpdef list[int] squares_C_API(int nsquares):\n",
    "  cdef int i, j = 2\n",
    "  cdef list result = PyList_New(nsquares)  # Preallocate list of appropriate size\n",
    "    \n",
    "  for i in range(nsquares):\n",
    "    PyList_SET_ITEM(result, i, i ** j)   # Directly set item in preallocated list using cython function\n",
    "    \n",
    "  return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5093e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit squares_C_API(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae469b",
   "metadata": {},
   "source": [
    "### \n",
    "### By pre-allocating a list of appropriate size and using `PyList_SET_ITEM` (the `C` API function for item assignment),\n",
    "### we were able to bypass the `Python` interpreter even more.\n",
    "\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### `Cython` has the advantage over `Numba` that you can pass and type declare\n",
    "### all `Python` built-ins and even custom objects in a `Cython` function.\n",
    "### \n",
    "### However, does `Cython` speed up non-vectorised `Numpy` code ?\n",
    "### Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51661892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Numpy normalization with a for loop \"\"\"\n",
    "def normalize_not_vectorised(arr: np.ndarray) -> np.ndarray:\n",
    "  \"Normalize a 2D array along the last axis. Not vectorised.\"\n",
    "    \n",
    "  assert arr.ndim == 2\n",
    "    \n",
    "  ret = np.empty(arr.shape, dtype=float)\n",
    "    \n",
    "  for i, subarr in enumerate(arr):\n",
    "    ret[i] = subarr / np.linalg.norm(subarr)\n",
    "  return ret\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - same but vectorized \"\"\"\n",
    "def normalize_vectorised(arr: np.ndarray) -> np.ndarray:\n",
    "  \"vectorised.\"\n",
    "  return arr / np.linalg.norm(arr, ord=2, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d678000",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - non-vectorized version but in Cython \"\"\"\n",
    "cpdef cnp.ndarray[cnp.float64_t, ndim=2] normalize_not_vectorised_cy(cnp.ndarray[cnp.float64_t, ndim=2] arr):\n",
    "  cdef:\n",
    "    int i\n",
    "    int rows = arr.shape[0]\n",
    "    int cols = arr.shape[1]\n",
    "    cnp.ndarray[cnp.float64_t, ndim=1] subarr\n",
    "    cnp.ndarray[cnp.float64_t, ndim=2] ret\n",
    "  \n",
    "  ret = np.empty((rows, cols), dtype=float)  # we have to do (arr.shape[0], arr.shape[1]) instead of arr.shape\n",
    "  \n",
    "  for i, subarr in enumerate(arr):\n",
    "    ret[i] = subarr / np.linalg.norm(subarr)\n",
    "  \n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b869429",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(10_000, 2)\n",
    "\n",
    "%timeit normalize_not_vectorised(arr)\n",
    "%timeit normalize_vectorised(arr)\n",
    "%timeit normalize_not_vectorised_cy(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367c0cf",
   "metadata": {},
   "source": [
    "### \n",
    "### The reason we didn't gain any speedups is because `Cython`, unlike `Numba`, still does\n",
    "### `Numpy` stuff from the `Python` interpreter. Here our code is bottlenecked by the `for` loop.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### We can pass `Numpy` arrays into `Cython` functions and `view` them as a so-called `Memoryview`.\n",
    "### A `Memoryview` is a view into the memory that is aware of its own shape.\n",
    "### Let us remove all `Python` overhead and see if we gain speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c26d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "import numpy as np\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - double[:, ::1] means 2D double array contiguous in memory \"\"\"\n",
    "cpdef double[:, ::1] normalize_cy(double[:, ::1] arr):\n",
    "  cdef:\n",
    "    int i, j\n",
    "    double norm\n",
    "    \n",
    "  cdef double[:, ::1] ret = np.empty((arr.shape[0], arr.shape[1]), dtype=np.double)\n",
    "  \n",
    "  # C style implementation\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    norm = 0.0\n",
    "    for j in range(arr.shape[1]):\n",
    "      norm += arr[i, j] ** 2\n",
    "    norm = sqrt(norm)\n",
    "    \n",
    "    for j in range(arr.shape[1]):\n",
    "      ret[i, j] = arr[i, j] / norm\n",
    "      \n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1717fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(10_000, 2)\n",
    "\n",
    "%timeit normalize_cy(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd92ed2",
   "metadata": {},
   "source": [
    "### \n",
    "### Even faster than the vectorised version because we didn't create an\n",
    "### intermediate array for the norm.\n",
    "### The only `Python` overhead left is the line:\n",
    "### `cdef double[:, ::1] ret = np.empty((arr.shape[0], arr.shape[1]), dtype=np.double)`\n",
    "### which creates a _smart_ array that is automatically deallocated (because it's handled by `Numpy`).\n",
    "### \n",
    "### We can speed up more by disabling bounds and division by zero checking, trading safety for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "cimport cython\n",
    "import numpy as np\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - same code but with bounds and zero division checking disabled \"\"\"\n",
    "@cython.boundscheck(False)\n",
    "@cython.cdivision(True)\n",
    "cpdef double[:, ::1] normalize_cy(double[:, ::1] arr):\n",
    "  cdef:\n",
    "    int i, j\n",
    "    double norm\n",
    "    \n",
    "  cdef double[:, ::1] ret = np.empty((arr.shape[0], arr.shape[1]), dtype=np.double)\n",
    "  \n",
    "  # C style implementation\n",
    "  for i in range(arr.shape[0]):\n",
    "    norm = 0.0\n",
    "    for j in range(arr.shape[1]):\n",
    "      norm += arr[i, j] ** 2\n",
    "    norm = sqrt(norm)\n",
    "    \n",
    "    for j in range(arr.shape[1]):\n",
    "      ret[i, j] = arr[i, j] / norm\n",
    "      \n",
    "  return np.asarray(ret)  # convert back to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(10_000, 2)\n",
    "\n",
    "%timeit normalize_cy(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b48351",
   "metadata": {},
   "source": [
    "### \n",
    "### It's not much but many pennies make a dollar ;-)\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### Just like `Numba`, `Cython` comes with `embarassing parallelisation` out of the box.\n",
    "### For this, we have to locally release the `GIL` (we have to import from external module\n",
    "### else the parallelisation doesn't work).\n",
    "### <u>Code</u> (just to show the code, it will raise an error if you run it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load cy/normalize/normalize.pyx\n",
    "\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "cimport cython\n",
    "from libc.math cimport sqrt\n",
    "from cython.parallel cimport prange\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:, ::1] _normalize_cy_parallel(double[:, ::1] arr):\n",
    "  cdef:\n",
    "    int i, j, shape0, shape1\n",
    "    double norm\n",
    "    double[:, ::1] ret\n",
    "\n",
    "  ret = np.empty((arr.shape[0], arr.shape[1]), dtype=np.double)\n",
    "  shape0, shape1 = arr.shape[0], arr.shape[1]\n",
    "\n",
    "  \"\"\" [FOCUS] - release the GIL \"\"\"\n",
    "  with nogil:\n",
    "\n",
    "    # embarassingly parallelise the outer loop\n",
    "    for i in prange(shape0):\n",
    "      norm = 0.0\n",
    "      for j in range(shape1):\n",
    "        norm += arr[i, j] ** 2\n",
    "      norm = sqrt(norm)\n",
    "\n",
    "      for j in range(shape1):\n",
    "        ret[i, j] = arr[i, j] / norm\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "def normalize_cy_parallel(double[:, ::1] arr):\n",
    "  return np.asarray(_normalize_cy_parallel(arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fad2d",
   "metadata": {},
   "source": [
    "### \n",
    "### Let's time the parallel version vs the sequential one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5272909",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(10_000_000, 20)\n",
    "\n",
    "import sys\n",
    "sys.path.append('cy/normalize')\n",
    "from normalize import normalize_cy_parallel\n",
    "\n",
    "%timeit normalize_cy(arr)\n",
    "%timeit normalize_cy_parallel(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599df0b",
   "metadata": {},
   "source": [
    "### Let's check if they give the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c61945",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(1000, 20)\n",
    "ret0 = normalize_cy(arr)\n",
    "ret1 = normalize_cy_parallel(arr)\n",
    "print(f\"The parallel and sequential version give the same output ? {np.allclose(ret0, ret1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93be292",
   "metadata": {},
   "source": [
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "### Not only does `Cython` allow you to use all `Python` concepts (arrays, classes, ...)\n",
    "### in a (partly) compiled environment, `Cython` also provides the infrastructure for\n",
    "### highly performant (but unsafe) `C`-style coding.\n",
    "### \n",
    "### It allows you to write `C`-style `struct`'s, `enum`'s and `union`'s, it provides\n",
    "### an interface to `libc` (the `C` standard library) and allows you to use all this\n",
    "### in a `Python`-like language. Meanwhile, you can still use external `Python` libraries\n",
    "### in your code, for instance `Sympy`.\n",
    "### \n",
    "### As a final example, here a piece of code that takes a math string, converts it into\n",
    "### a `Cython` struct that represents it and then allows you to evaluate it from `Python`.\n",
    "### The code is `embarassingly` parallelised and could be further used within a low-level\n",
    "### `Cython` environment, for instance one that highly efficiently assembles a FEM matrix.\n",
    "### \n",
    "### <u>The code operates as follows</u>:\n",
    "### 1. Pass a math string and an array of coordinates.\n",
    "### 2. Use `Sympy` to deconstruct the math string into a sequence of mathematical operations.\n",
    "### 3. Represent the sequence in a `Cython` struct.\n",
    "### 4. Pass to a low-level function that evaluates the math expression in the coordinates.\n",
    "### \n",
    "### The low-level implementation uses basic `C`-style concepts like `malloc` (memory allocation)\n",
    "### pointers and freeing memory.\n",
    "###\n",
    "### **YOU DO NOT HAVE TO UNDERSTAND ALL THE DETAILS.**\n",
    "### **THIS EXAMPLE SHOWS YOU HOW YOU CAN COMBINE CONCEPTS FROM BOTH**\n",
    "### **PYTHON AND C TO ACHIEVE FUNCTIONALITY AND PERFORMANCE.**\n",
    "### \n",
    "### First a so-called definition file, declaring all structs, enums, unions and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331a223-e23b-45fc-a1b2-b11657f3a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load cy/expression_tree/tree.pxd\n",
    "#cython: language_level=3\n",
    "\n",
    "# [HELPER] - enum tokenizing various mathematical functions\n",
    "cdef enum ExpressionType:\n",
    "  CONSTANT,\n",
    "  VARIABLE,\n",
    "  EXP,\n",
    "  SIN,\n",
    "  COS,\n",
    "  ADD,\n",
    "  MULTIPLY,\n",
    "  POWER\n",
    "\n",
    "\n",
    "# [HELPER] - Structs representing the different mathematical operations\n",
    "\n",
    "\n",
    "# f(x) = value\n",
    "cdef struct Constant:\n",
    "  double value\n",
    "\n",
    "\n",
    "# f(x0, ..., xn) = xi;  token: 0 for `x0` 1 for `x1`...\n",
    "cdef struct Variable:\n",
    "  int token\n",
    "\n",
    "\n",
    "# Addition, multiplication, ... between several args\n",
    "cdef struct ArithmeticOperation:\n",
    "  int nargs              # number of arguments\n",
    "  Expression* arguments  # pointer to first position of array of arguments\n",
    "\n",
    "\n",
    "# f(x)^g(x)\n",
    "cdef struct Power:\n",
    "  Expression* base\n",
    "  Expression* exponent\n",
    "\n",
    "\n",
    "# exp(f(x)), sin(f(x)), cos(f(x)), ...\n",
    "cdef struct Function:\n",
    "  Expression* argument\n",
    "\n",
    "\n",
    "# [HELPER] - Expression union combining all math structs\n",
    "cdef union ExpressionUnion:\n",
    "  Constant constant\n",
    "  Variable variable\n",
    "  ArithmeticOperation arithmeticOperation\n",
    "  Function function\n",
    "  Power power\n",
    "\n",
    "\n",
    "# Struct holding a token of the expression type\n",
    "# and the corresponding expression as an ExpressionUnion\n",
    "\n",
    "# Example:\n",
    "\n",
    "# type: ExpressionType.EXP\n",
    "# expression: ExpressionUnion with expression.function = struct Function(*argument)\n",
    "\n",
    "# [HELPER] - Expression struct combining the type and the expression\n",
    "cdef struct Expression:\n",
    "  ExpressionType type\n",
    "  ExpressionUnion expression\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "### Forward definitions of select functions defined in the main script.\n",
    "\n",
    "cdef Expression parse_math_string(str math_string)\n",
    "cdef void eval_expression_vectorized(Expression expr, double[:, ::1] arg, double* into) except *\n",
    "cdef void free_Expression(Expression* expression)\n",
    "\n",
    "\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65aa2c",
   "metadata": {},
   "source": [
    "### \n",
    "### Now a concrete implementation of the declared objects (do not focus on the details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load cy/expression_tree/tree.pyx\n",
    "# distutils: extra_compile_args = -fopenmp\n",
    "# distutils: extra_link_args = -fopenmp\n",
    "\n",
    "\"\"\" [IMPORT] \"\"\"\n",
    "cimport cython\n",
    "from cython.parallel cimport prange\n",
    "from cython.view cimport array\n",
    "from sympy import parse_expr\n",
    "\n",
    "from libc.stdlib cimport abort, malloc, free\n",
    "from libc.math cimport exp as cexp, sin as csin, cos as ccos\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" Expression constructors and destructor \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - various expression constructors \"\"\"\n",
    "\n",
    "\n",
    "cdef Expression make_ArithmeticOperation(ExpressionType type, Expression* args, int nargs):\n",
    "  \"\"\"\n",
    "    Construct an :Expression: ret with\n",
    "        ret.type = type (must be ADD or MULTIPLY)\n",
    "        ret.expression.arithmeticOperation.arguments = args and\n",
    "        ret.expression.arithmeticOperation.nargs = nargs.\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    Expression ret\n",
    "    ExpressionUnion expr\n",
    "    ArithmeticOperation arop\n",
    "\n",
    "  if not type in (ADD, MULTIPLY):\n",
    "    abort()\n",
    "\n",
    "  ret.type = type\n",
    "  arop.arguments = args\n",
    "  arop.nargs = nargs\n",
    "  expr.arithmeticOperation = arop\n",
    "  ret.expression = expr\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "cdef Expression make_Constant(double value):\n",
    "  \"\"\"\n",
    "    Construct an :Expression: ret with\n",
    "    ret.type = CONSTANT\n",
    "    ret.expression.constant = Constant(value)\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    Expression ret\n",
    "    ExpressionUnion expr\n",
    "\n",
    "  expr.constant = Constant(value)\n",
    "  ret.type = CONSTANT\n",
    "  ret.expression = expr\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "cdef Expression make_Variable(int token):\n",
    "  \"\"\"\n",
    "    Construct an :Expression: ret with\n",
    "    ret.type = VARIABLE\n",
    "    ret.expression.variable.token = token\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    Expression ret\n",
    "    ExpressionUnion expr\n",
    "\n",
    "  assert token >= 0\n",
    "\n",
    "  expr.variable = Variable(token)\n",
    "  ret.type = VARIABLE\n",
    "  ret.expression = expr\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "cdef Expression make_Function(ExpressionType type, Expression* arg):\n",
    "  \"\"\"\n",
    "    Construct an :Expression: ret with\n",
    "    ret.type = type, where type is either EXP, SIN or COS and\n",
    "    ret.expression.function.argument = arg\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    Expression ret\n",
    "    ExpressionUnion expr\n",
    "    Function func\n",
    "\n",
    "  if not type in (EXP, SIN, COS):\n",
    "    abort()\n",
    "\n",
    "  ret.type = type\n",
    "  func.argument = arg\n",
    "  expr.function = func\n",
    "  ret.expression = expr\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "cdef Expression make_Exponent(Expression* base, Expression* exponent):\n",
    "  \"\"\"\n",
    "    Construct an :Expression: ret with\n",
    "    ret.type = POWER\n",
    "    ret.expression.power.base = base\n",
    "    ret.expression.power.exponent = exponent\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    Expression ret\n",
    "    ExpressionUnion expr\n",
    "\n",
    "  expr.power = Power(base, exponent)\n",
    "  ret.type = POWER\n",
    "  ret.expression = expr\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - deallocate a variable of type `Expression` \"\"\"\n",
    "cdef void free_Expression(Expression* expression):\n",
    "  cdef:\n",
    "    int i\n",
    "\n",
    "  if expression.type in (ADD, MULTIPLY):\n",
    "\n",
    "    for i in range(expression.expression.arithmeticOperation.nargs):\n",
    "      free_Expression(&expression.expression.arithmeticOperation.arguments[i])\n",
    "    free(expression.expression.arithmeticOperation.arguments)\n",
    "\n",
    "  elif expression.type in (EXP, SIN, COS):\n",
    "\n",
    "    free_Expression(&expression.expression.function.argument[0])\n",
    "    free(expression.expression.function.argument)\n",
    "\n",
    "  elif expression.type == POWER:\n",
    "\n",
    "    free_Expression(&expression.expression.power.base[0])\n",
    "    free_Expression(&expression.expression.power.exponent[0])\n",
    "    free(expression.expression.power.base)\n",
    "    free(expression.expression.power.exponent)\n",
    "\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" MATHEMATICAL FUNCTION EVALUATION \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Evaluate a mathematical expression \"\"\"\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.initializedcheck(False)\n",
    "cdef double eval_expression(Expression expr, double[:] args) nogil:\n",
    "  \"\"\"\n",
    "    Evaluate a :struct: Expression representing a mathematical function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expr: :struct: Expression\n",
    "      The struct instantiation representing the mathematical function.\n",
    "    args: :struct: double[:]\n",
    "      The 1D memoryview representing the coordinate to evaluate in.\n",
    "      If args.shape[0] does not equal the number of arguments in `expr`,\n",
    "      a segfault may occur.\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    double ret\n",
    "    int i\n",
    "\n",
    "  if expr.type == CONSTANT:\n",
    "    return expr.expression.constant.value\n",
    "  elif expr.type == VARIABLE:\n",
    "    return args[expr.expression.variable.token]\n",
    "  elif expr.type == ADD:\n",
    "    ret = 0.0\n",
    "    for i in range(expr.expression.arithmeticOperation.nargs):\n",
    "      ret += eval_expression(expr.expression.arithmeticOperation.arguments[i], args)\n",
    "    return ret\n",
    "  elif expr.type == MULTIPLY:\n",
    "    ret = 1.0\n",
    "    for i in range(expr.expression.arithmeticOperation.nargs):\n",
    "      ret *= eval_expression(expr.expression.arithmeticOperation.arguments[i], args)\n",
    "    return ret\n",
    "  elif expr.type == POWER:\n",
    "    return eval_expression(expr.expression.power.base[0], args) ** \\\n",
    "           eval_expression(expr.expression.power.exponent[0], args)\n",
    "  elif expr.type == EXP:\n",
    "    return cexp(eval_expression(expr.expression.function.argument[0], args))\n",
    "  elif expr.type == SIN:\n",
    "    return csin(eval_expression(expr.expression.function.argument[0], args))\n",
    "  elif expr.type == COS:\n",
    "    return ccos(eval_expression(expr.expression.function.argument[0], args))\n",
    "  else:\n",
    "    abort()\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Evaluate a mathematical expression vectorized (and parallelized) \"\"\"\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.initializedcheck(False)\n",
    "cdef void eval_expression_vectorized(Expression expr, double[:, ::1] arg, double* into) except *:\n",
    "  \"\"\"\n",
    "    Evaluate a :struct: Expression representing a mathematical function in an array of coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expr: :struct: Expression\n",
    "      The struct instantiation representing the mathematical function.\n",
    "    args: :struct: double[:, ::1]\n",
    "      The 2D memoryview representing the coordinates to evaluate in.\n",
    "      If args.shape[1] does not equal the number of arguments in `expr`,\n",
    "      a segfault may occur.\n",
    "    into: double*\n",
    "      A pointer to the first entry of the preallocated array to iterate the\n",
    "      result into.\n",
    "  \"\"\"\n",
    "  cdef int i\n",
    "  with nogil:\n",
    "    for i in prange(arg.shape[0]):\n",
    "      into[i] = eval_expression(expr, arg[i])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" MATH STRING PARSING \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - use sympy to decompose a string into a list of lists of mathematical operations \"\"\"\n",
    "def decompose_expression(expr):\n",
    "  \"\"\"\n",
    "    Given a sympy expression `expr` create a list of lists representing\n",
    "    the sympy expression using primitive types (strings, floats, ...)\n",
    "  \"\"\"\n",
    "  cdef str name = expr.func.__name__\n",
    "  if name in ('Add', 'Mul'):\n",
    "    args = expr.args\n",
    "    decomposed_args = [decompose_expression(arg) for arg in args]\n",
    "    return [name, decomposed_args]\n",
    "  elif name == 'Pow':\n",
    "    args = expr.args\n",
    "    return [name, [decompose_expression(arg) for arg in args]]\n",
    "  elif name in ('exp', 'sin', 'cos'):\n",
    "    arg, = expr.args\n",
    "    return [name, [decompose_expression(arg)]]\n",
    "  else:\n",
    "    try:\n",
    "      return [float(str(expr)), []]\n",
    "    except Exception:\n",
    "      ret = str(expr)\n",
    "      assert ret.startswith('x')\n",
    "      assert int(ret[1:]) >= 0\n",
    "      return [ret, []]\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - Convert a list of lists into a Cython expression \"\"\"\n",
    "cdef Expression expression_from_list_of_lists(list lol):\n",
    "  \"\"\"\n",
    "    Convert a list of lists comprised of primitives (strings, floats, ...)\n",
    "    into an instance of `Expression`, to be used in `eval_expression_vectorized`.\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    int nargs\n",
    "    Expression* base\n",
    "    Expression* exponent\n",
    "    Expression* args\n",
    "\n",
    "  head, tail = lol\n",
    "  nargs = len(tail)\n",
    "\n",
    "  cdef Expression ret\n",
    "\n",
    "  if head in ('Mul', 'Add'):\n",
    "\n",
    "    assert nargs >= 2\n",
    "    args = <Expression*>malloc(nargs * sizeof(Expression))\n",
    "    for i in range(nargs):\n",
    "      args[i] = expression_from_list_of_lists(tail[i])\n",
    "    return make_ArithmeticOperation({'Add': ADD, 'Mul': MULTIPLY}[head], &args[0], nargs)\n",
    "\n",
    "  elif head in ('exp', 'sin', 'cos'):\n",
    "\n",
    "    assert nargs == 1\n",
    "    args = <Expression*>malloc(1 * sizeof(Expression))\n",
    "    args[0] = expression_from_list_of_lists(tail[0])\n",
    "    return make_Function({'exp': EXP, 'sin': SIN, 'cos': COS}[head], &args[0])\n",
    "\n",
    "  elif head == 'Pow':\n",
    "\n",
    "    assert nargs == 2\n",
    "    base = <Expression*>malloc(sizeof(Expression))\n",
    "    exponent = <Expression*>malloc(sizeof(Expression))\n",
    "    base[0] = expression_from_list_of_lists(tail[0])\n",
    "    exponent[0] = expression_from_list_of_lists(tail[1])\n",
    "    return make_Exponent(&base[0], &exponent[0])\n",
    "\n",
    "  else:\n",
    "\n",
    "    if isinstance(head, str):\n",
    "      assert head.startswith('x')\n",
    "      return make_Variable(int(head[1:]))\n",
    "\n",
    "    return make_Constant(float(head))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - use 1) `decompose_expression` and\n",
    "                  2) `expression_from_list_of_lists`\n",
    "                  to create a Cython expression from a math string \"\"\"\n",
    "cdef Expression parse_math_string(str math_string):\n",
    "\n",
    "  # convert math string to sympy object\n",
    "  sympy_expression = parse_expr(math_string)\n",
    "\n",
    "  # decompost sympy expression into a tree of mathematical operations\n",
    "  decomposed_expression = decompose_expression(sympy_expression)\n",
    "\n",
    "  # create a cython expression representing the tree\n",
    "  expr = expression_from_list_of_lists(decomposed_expression)\n",
    "\n",
    "  return expr\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - Function to evaluate a mathematical string, callable from pure Python \"\"\"\n",
    "def evaluate_math_string(str math_string, x):\n",
    "  \"\"\"\n",
    "    Evaluate a function by its mathematical string representation.\n",
    "    The function can take several arguments, which are denoted by\n",
    "    x0, x1, ...\n",
    "    The position `x` must have shape (N, n), where `n` is the\n",
    "    number of arguments in the string.\n",
    "\n",
    "    >>> x = np.array([[1.0, 0], [0.0, 1.0]])\n",
    "    >>> math_string = 'x0 - x1'\n",
    "    >>> evaluate_math_string(math_string, x)\n",
    "      np.array([1.0, -1.0])\n",
    "  \"\"\"\n",
    "  cdef:\n",
    "    double[::1] into\n",
    "    Expression expr\n",
    "\n",
    "  # allocate flat memory for return array\n",
    "  into = np.empty((np.prod(x.shape[:-1]),), dtype=np.float64)\n",
    "\n",
    "  # convert math string to cython expression\n",
    "  expr = parse_math_string(math_string)\n",
    "\n",
    "  # evaluate cython expression in `x` reshaped to shape (N, n) where `n`\n",
    "  # is the number of variables. Iterate the result into `into`.\n",
    "  eval_expression_vectorized(expr, x.reshape(-1, x.shape[-1]), &into[0])\n",
    "\n",
    "  # deallocate cython expression\n",
    "  free_Expression(&expr)\n",
    "\n",
    "  # convert to numpy array, reshape to original shape and return\n",
    "  return np.asarray(into).reshape(x.shape[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b2b7a",
   "metadata": {},
   "source": [
    "### \n",
    "### Let's test our implementation.\n",
    "### Since it supports more than one argument, we make a surface plot of a standing wave over $[0, 1]^2$:\n",
    "### $f(x_0, x_1) = \\sin(\\pi x_0) \\sin(\\pi x_1) + 2 \\sin(2 \\pi x_0) \\sin(2 \\pi x_1) + 4 \\sin(3 \\pi x_0) \\sin(3 \\pi x_1)$\n",
    "### \n",
    "### We use the cython function to evaluate the math string and matplotlib to plot the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [IMPORT] \"\"\"\n",
    "import sys\n",
    "sys.path.append('cy/expression_tree')\n",
    "from tree import evaluate_math_string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import the 3D plotting toolkit\n",
    "\n",
    "\n",
    "\"\"\" [HELPER] - plot X, Y vs Z \"\"\"\n",
    "def plot_surface(X, Y, Z):\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "  # Plot the surface\n",
    "  surf = ax.plot_surface(X, Y, Z, cmap='viridis')  # Use a colormap of your choice\n",
    "\n",
    "  # Add color bar which maps values to colors\n",
    "  fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "  # Labels and title\n",
    "  ax.set_xlabel('X coordinate')\n",
    "  ax.set_ylabel('Y coordinate')\n",
    "  ax.set_zlabel('Z value')\n",
    "  ax.set_title('Surface Plot of f(x, y)')\n",
    "\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "\"\"\" [SETUP] - standing wave with higher-order harmonics \"\"\"\n",
    "math_string = f'sin({np.pi} * x0) * sin({np.pi} * x1) +' \\\n",
    "              f'2 * sin(2 * {np.pi} * x0) * sin(2 * {np.pi} * x1) +' \\\n",
    "              f'4 * sin(3 * {np.pi} * x0) * sin(3 * {np.pi} * x1)'\n",
    "\n",
    "\n",
    "\"\"\" [SETUP] - create meshgrid \"\"\"\n",
    "x = np.linspace(0, 1, 5001)\n",
    "y = np.linspace(0, 1, 5001)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "\"\"\" [FOCUS] - evaluate math string in Cython \"\"\"\n",
    "print(f\"Evaluating the the math string in {len(x) * len(y)} points.\\n\")\n",
    "Z = evaluate_math_string(math_string, np.stack([X, Y], axis=-1))\n",
    "\n",
    "\n",
    "plot_surface(X, Y, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd6af8",
   "metadata": {},
   "source": [
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "# <u> What we have learned: </u>\n",
    "### 1. `Cython` allows you to type declare your `Python` code which can lead to speedups.\n",
    "### 2. Do not expect significant speedups if your code is bottlenecked by a `Numpy` operation in a loop.\n",
    "### 3. Memoryviews allow you to implement `ndarray` operations in a `C`-style fashion, with `C` performance.\n",
    "### 4. `Cython` gives you the tools to do even lower-level `C`-style programming while still allowing\n",
    "### you to use the rich `Python` eccosystem in your code.\n",
    "### 5. To benefit from all advanced `Cython` features, unlike in `Numba`, you have to **learn** `Cython`.\n",
    "### \n",
    "<hr style=\"border:1px solid blue\">\n",
    "\n",
    "### \n",
    "## **I hope you enjoyed this seminar on advanced `Python` concepts.**\n",
    "### \n",
    "### Here some additional techniques to speed up your code:\n",
    "### 1. Binding a `C` code using the built-in `Python` module `ctypes`.\n",
    "### 2. Binding `C++` using `Cython` (yes it can also do that) `pybind11`, `Boost.Python`, ...\n",
    "### 3. Pypy\n",
    "### 4. JAX (like Numba but for optimization, machine learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8637f6-f147-4b8c-a270-6abc83717e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
